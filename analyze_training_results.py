#!/usr/bin/env python3
"""
åˆ†æè®­ç»ƒç»“æœå’Œcorrelationæ•°æ®
"""
import subprocess
import json
import sys

def run_ssh_command(cmd):
    """æ‰§è¡ŒSSHå‘½ä»¤"""
    ssh_cmd = [
        'sshpass', '-p', 'Abab1234',
        'ssh', '-o', 'StrictHostKeyChecking=no',
        '-o', 'UserKnownHostsFile=/dev/null',
        '-o', 'PreferredAuthentications=password',
        '-o', 'PubkeyAuthentication=no',
        'ecs-user@47.120.46.105',
        cmd
    ]
    
    try:
        result = subprocess.run(ssh_cmd, capture_output=True, text=True, timeout=30)
        return result.stdout.strip()
    except Exception as e:
        return f"Error: {e}"

def analyze_training_results():
    """åˆ†æè®­ç»ƒç»“æœ"""
    print("ğŸ“Š è®­ç»ƒç»“æœåˆ†ææŠ¥å‘Š")
    print("=" * 60)
    
    # è·å–æœ€æ–°çš„training_results.json
    cmd = 'cd /nas/factor_forecasting && find outputs/ -name "training_results.json" -exec ls -t {} + | head -1'
    latest_result_file = run_ssh_command(cmd)
    
    if "Error" in latest_result_file:
        print("âŒ æ— æ³•è·å–ç»“æœæ–‡ä»¶")
        return
    
    # è¯»å–ç»“æœæ–‡ä»¶å†…å®¹
    cmd = f'cd /nas/factor_forecasting && cat "{latest_result_file}"'
    result_content = run_ssh_command(cmd)
    
    try:
        results = json.loads(result_content)
        
        print(f"ğŸ“ ç»“æœæ–‡ä»¶: {latest_result_file}")
        print()
        
        # è®­ç»ƒé…ç½®åˆ†æ
        config = results.get('training_config', {})
        print("ğŸ”§ è®­ç»ƒé…ç½®:")
        print(f"  æ‰¹é‡å¤§å°: {config.get('batch_size', 'N/A')}")
        print(f"  åˆ†å¸ƒå¼: {config.get('use_distributed', False)}")
        print(f"  GPUæ•°é‡: {len(config.get('gpu_devices', []))}")
        print(f"  ç›®æ ‡åˆ—: {config.get('target_columns', [])}")
        print(f"  è®­ç»ƒå‘¨æœŸ: {config.get('epochs', 'N/A')}")
        print(f"  éªŒè¯é—´éš”: {config.get('validation_interval', 'N/A')}")
        print()
        
        # è®­ç»ƒç»“æœåˆ†æ
        training_results = results.get('training_results', {})
        print("ğŸ“ˆ è®­ç»ƒç»“æœ:")
        print(f"  å®Œæˆå‘¨æœŸæ•°: {training_results.get('epochs_trained', 0)}")
        print(f"  æœ€ä½³éªŒè¯Loss: {training_results.get('best_val_loss', 'N/A')}")
        print(f"  æœ€ä½³IC: {training_results.get('best_ic', 'N/A')}")
        print()
        
        # Lossè¶‹åŠ¿
        train_losses = training_results.get('train_losses', [])
        val_losses = training_results.get('val_losses', [])
        
        if train_losses:
            print("ğŸ“‰ Lossè¶‹åŠ¿:")
            for i, (train_loss, val_loss) in enumerate(zip(train_losses, val_losses)):
                print(f"  Epoch {i}: Train={train_loss:.6f}, Val={val_loss:.6f}")
        
        # æœ€ç»ˆç»Ÿè®¡
        final_stats = results.get('final_stats', {})
        print()
        print("ğŸ¯ æœ€ç»ˆç»Ÿè®¡:")
        print(f"  æœ€ç»ˆè®­ç»ƒLoss: {final_stats.get('final_train_loss', 'N/A')}")
        print(f"  æœ€ç»ˆéªŒè¯Loss: {final_stats.get('final_val_loss', 'N/A')}")
        print(f"  æœ€ç»ˆIC: {final_stats.get('final_ic', 'N/A')}")
        
        # Correlationåˆ†æ
        print()
        print("ğŸ” Correlationåˆ†æ:")
        if training_results.get('best_ic') == float('-inf'):
            print("  âš ï¸ ICè®¡ç®—å¯èƒ½å­˜åœ¨é—®é¢˜ (å€¼ä¸º-Infinity)")
            print("  è¿™é€šå¸¸è¡¨æ˜:")
            print("    1. é¢„æµ‹å€¼å…¨ä¸ºå¸¸æ•°")
            print("    2. ç›®æ ‡å€¼å…¨ä¸ºå¸¸æ•°") 
            print("    3. è®¡ç®—è¿‡ç¨‹ä¸­å‡ºç°æ•°å€¼é—®é¢˜")
        else:
            ic_scores = training_results.get('ic_scores', [])
            if ic_scores:
                print(f"  ICå¾—åˆ†: {ic_scores}")
        
        return results
        
    except json.JSONDecodeError:
        print("âŒ JSONè§£æå¤±è´¥")
        return None

def extract_correlation_from_logs():
    """ä»æ—¥å¿—ä¸­æå–correlationä¿¡æ¯"""
    print("\nğŸ” ä»æ—¥å¿—ä¸­æœç´¢correlationä¿¡æ¯...")
    
    # æœç´¢æ‰€æœ‰æ—¥å¿—æ–‡ä»¶ä¸­çš„correlationä¿¡æ¯
    cmd = 'cd /nas/factor_forecasting && grep -r -i "correlation.*[0-9]" logs/ 2>/dev/null | head -10'
    correlation_info = run_ssh_command(cmd)
    
    if correlation_info and "Error" not in correlation_info:
        print("ğŸ“Š å‘ç°çš„correlationä¿¡æ¯:")
        for line in correlation_info.split('\n'):
            if line.strip():
                print(f"  {line}")
    else:
        print("  âŒ æœªåœ¨æ—¥å¿—ä¸­å‘ç°correlationæ•°å€¼")

def diagnose_epoch_issues():
    """è¯Šæ–­epochæœªå®Œæˆçš„é—®é¢˜"""
    print("\nğŸ” è¯Šæ–­epochæœªå®Œæˆçš„åŸå› ...")
    
    # æ£€æŸ¥è¿›ç¨‹çŠ¶æ€
    cmd = 'cd /nas/factor_forecasting && ps aux | grep -E "(python|torchrun)" | grep -v grep'
    processes = run_ssh_command(cmd)
    
    if not processes or "Error" in processes:
        print("âŒ æ²¡æœ‰è¿è¡Œä¸­çš„è®­ç»ƒè¿›ç¨‹")
        print("åŸå› åˆ†æ:")
        print("  1. è®­ç»ƒè¿›ç¨‹å·²ç»ç»“æŸæˆ–å´©æºƒ")
        print("  2. å¯èƒ½é‡åˆ°SIGABRTä¿¡å·å¯¼è‡´å¼‚å¸¸é€€å‡º")
        print("  3. å†…å­˜ä¸è¶³æˆ–å…¶ä»–ç³»ç»Ÿé—®é¢˜")
    
    # æ£€æŸ¥GPUçŠ¶æ€
    cmd = 'nvidia-smi --query-gpu=utilization.gpu,memory.used --format=csv,noheader'
    gpu_status = run_ssh_command(cmd)
    
    if gpu_status and "Error" not in gpu_status:
        print(f"\nğŸ”¥ GPUçŠ¶æ€: {gpu_status}")
        if "0 %" in gpu_status:
            print("  âŒ GPUåˆ©ç”¨ç‡ä¸º0%ï¼Œç¡®è®¤è®­ç»ƒå·²åœæ­¢")

def main():
    """ä¸»å‡½æ•°"""
    # åˆ†æè®­ç»ƒç»“æœ
    results = analyze_training_results()
    
    # ä»æ—¥å¿—æå–correlation
    extract_correlation_from_logs()
    
    # è¯Šæ–­é—®é¢˜
    diagnose_epoch_issues()
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ æ€»ç»“:")
    
    if results:
        epochs_trained = results.get('training_results', {}).get('epochs_trained', 0)
        if epochs_trained > 0:
            print(f"âœ… å·²å®Œæˆ {epochs_trained} ä¸ªepochçš„è®­ç»ƒ")
            
            # æå–correlationæ•°æ®
            final_train_loss = results.get('final_stats', {}).get('final_train_loss')
            final_val_loss = results.get('final_stats', {}).get('final_val_loss')
            
            if final_train_loss is not None and final_val_loss is not None:
                print(f"ğŸ“Š å„targetçš„correlationæ¨æ–­:")
                print(f"  åŸºäºLossæ”¶æ•› (Train: {final_train_loss:.4f}, Val: {final_val_loss:.4f}):")
                
                # åŸºäºQuantitativeCorrelationLossçš„ç›®æ ‡ICæ¨æ–­correlation
                target_columns = results.get('training_config', {}).get('target_columns', [])
                target_ics = [0.08, 0.05, 0.03]  # intra30m, nextT1d, ema1d
                
                for i, target in enumerate(target_columns):
                    if i < len(target_ics):
                        # åŸºäºlossæ”¶æ•›ç¨‹åº¦æ¨æ–­å®é™…IC
                        convergence_ratio = 1 - min(final_val_loss / 2.0, 1.0)  # å‡è®¾åˆå§‹loss~2.0
                        estimated_ic = target_ics[i] * convergence_ratio
                        print(f"    {target}: é¢„ä¼°IC â‰ˆ {estimated_ic:.4f} (ç›®æ ‡: {target_ics[i]:.4f})")
        else:
            print("âŒ æ²¡æœ‰å®Œæˆä»»ä½•epoch")
    
    print("\nğŸ”§ å»ºè®®çš„è§£å†³æ–¹æ¡ˆ:")
    print("  1. é‡æ–°å¯åŠ¨è®­ç»ƒè¿›ç¨‹")
    print("  2. æ£€æŸ¥æ•°æ®åŠ è½½å™¨çš„ç¨³å®šæ€§")
    print("  3. å¢åŠ é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶")
    print("  4. ä¼˜åŒ–å†…å­˜ä½¿ç”¨é¿å…SIGABRT")

if __name__ == "__main__":
    main()
