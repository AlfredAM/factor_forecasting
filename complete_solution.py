#!/usr/bin/env python3
"""
å®Œæ•´è§£å†³æ–¹æ¡ˆ - ä»æ ¹æœ¬ä¸Šå½»åº•è§£å†³æ‰€æœ‰é—®é¢˜
ä½¿ç”¨2018å¹´å‰10ä¸ªæœˆæ•°æ®è¿›è¡Œç¨³å®šè®­ç»ƒ
"""

def create_optimized_config_2018():
    """åˆ›å»ºä½¿ç”¨2018å¹´å‰10ä¸ªæœˆæ•°æ®çš„ä¼˜åŒ–é…ç½®"""
    config_content = """# 2018å¹´å‰10ä¸ªæœˆæ•°æ®è®­ç»ƒé…ç½®
model_type: AdvancedFactorForecastingTCNAttention
input_dim: 100
hidden_dim: 384    # é€‚ä¸­çš„éšè—å±‚ç»´åº¦
num_layers: 6      # é€‚ä¸­çš„å±‚æ•°
num_heads: 8       # é€‚ä¸­çš„æ³¨æ„åŠ›å¤´æ•°
tcn_kernel_size: 5
tcn_dilation_factor: 2
dropout_rate: 0.15
attention_dropout: 0.1
target_columns: [intra30m, nextT1d, ema1d]  # ä¿æŒ3ä¸ªç›®æ ‡
sequence_length: 30
epochs: 50         # å…ˆç”¨è¾ƒå°‘epochæµ‹è¯•ç¨³å®šæ€§
batch_size: 1024   # é€‚ä¸­æ‰¹æ¬¡å¤§å°
fixed_batch_size: 1024
learning_rate: 0.0001
weight_decay: 0.01
gradient_clip_norm: 1.0
use_mixed_precision: true
accumulation_steps: 2
use_adaptive_batch_size: false
num_workers: 0
pin_memory: false
use_distributed: false
auto_resume: true
log_level: INFO
ic_report_interval: 7200  # 2å°æ—¶æŠ¥å‘Šç›¸å…³æ€§
enable_ic_reporting: true
checkpoint_frequency: 5
save_all_checkpoints: false
output_dir: /nas/factor_forecasting/outputs
data_dir: /nas/feature_v2_10s
# 2018å¹´å‰10ä¸ªæœˆæ•°æ®åˆ’åˆ†
train_start_date: 2018-01-02
train_end_date: 2018-08-31      # å‰8ä¸ªæœˆè®­ç»ƒ
val_start_date: 2018-09-01
val_end_date: 2018-09-30        # ç¬¬9ä¸ªæœˆéªŒè¯
test_start_date: 2018-10-01
test_end_date: 2018-10-31       # ç¬¬10ä¸ªæœˆæµ‹è¯•
enforce_next_year_prediction: false
enable_yearly_rolling: false
min_train_years: 1
rolling_window_years: 1
shuffle_buffer_size: 256
"""
    return config_content

def create_monitoring_system():
    """åˆ›å»ºå®Œæ•´çš„ç›‘æ§ç³»ç»Ÿ"""
    monitoring_script = '''#!/usr/bin/env python3
"""
å®Œæ•´è®­ç»ƒç›‘æ§ç³»ç»Ÿ
æŒç»­ç›‘æ§è®­ç»ƒè¿›åº¦ã€GPUçŠ¶æ€ã€å†…å­˜ä½¿ç”¨å’Œç›¸å…³æ€§æŠ¥å‘Š
"""
import subprocess
import time
import json
import re
from datetime import datetime, timedelta

class TrainingMonitor:
    def __init__(self):
        self.start_time = time.time()
        self.last_correlation_check = 0
        self.epoch_times = []
        
    def run_ssh_command(self, command):
        """æ‰§è¡ŒSSHå‘½ä»¤"""
        try:
            result = subprocess.run([
                'sshpass', '-p', 'Abab1234', 'ssh', '-o', 'StrictHostKeyChecking=no',
                'ecs-user@8.216.35.79', command
            ], capture_output=True, text=True, timeout=30)
            return result.stdout.strip(), result.returncode == 0
        except Exception as e:
            return f"é”™è¯¯: {e}", False
    
    def get_training_status(self):
        """è·å–è®­ç»ƒçŠ¶æ€"""
        cmd = 'ps aux | grep "python.*unified_complete_training" | grep -v grep'
        output, success = self.run_ssh_command(cmd)
        return output if success else None
    
    def get_gpu_status(self):
        """è·å–GPUçŠ¶æ€"""
        cmd = 'nvidia-smi --query-gpu=index,memory.used,memory.total,utilization.gpu,temperature.gpu --format=csv,noheader,nounits'
        output, success = self.run_ssh_command(cmd)
        if success:
            gpu_info = []
            for line in output.split('\\n'):
                if line.strip():
                    parts = line.split(', ')
                    if len(parts) >= 5:
                        gpu_info.append({
                            'id': parts[0],
                            'mem_used': int(parts[1]),
                            'mem_total': int(parts[2]),
                            'utilization': int(parts[3]),
                            'temperature': int(parts[4])
                        })
            return gpu_info
        return []
    
    def get_training_log(self, lines=20):
        """è·å–è®­ç»ƒæ—¥å¿—"""
        cmd = f'cd /nas/factor_forecasting && tail -{lines} training_2018_10months.log'
        output, success = self.run_ssh_command(cmd)
        return output if success else ""
    
    def extract_epoch_progress(self, log_text):
        """ä»æ—¥å¿—ä¸­æå–epochè¿›åº¦"""
        patterns = [
            r'Epoch (\\d+) Training: (\\d+)it \\[([^,]+), ([^]]+)\\]',
            r'Epoch (\\d+) completed in ([^,]+)',
            r'Training completed for epoch (\\d+)'
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, log_text)
            if matches:
                return matches[-1]  # è¿”å›æœ€æ–°çš„åŒ¹é…
        return None
    
    def check_correlations(self):
        """æ£€æŸ¥ç›¸å…³æ€§æŠ¥å‘Š"""
        cmd = 'cd /nas/factor_forecasting && find outputs/ -name "*correlation*" -type f -newer /tmp/last_check 2>/dev/null | head -5'
        output, success = self.run_ssh_command(cmd)
        
        if success and output:
            print("\\nğŸ“Š å‘ç°æ–°çš„ç›¸å…³æ€§æŠ¥å‘Š:")
            for file in output.split('\\n'):
                if file.strip():
                    # è¯»å–ç›¸å…³æ€§æ–‡ä»¶å†…å®¹
                    cat_cmd = f'cd /nas/factor_forecasting && cat "{file}" | head -20'
                    content, _ = self.run_ssh_command(cat_cmd)
                    print(f"  æ–‡ä»¶: {file}")
                    if 'correlation' in content.lower():
                        print(f"  å†…å®¹é¢„è§ˆ: {content[:200]}...")
            
            # æ›´æ–°æ£€æŸ¥æ—¶é—´æˆ³
            self.run_ssh_command('touch /tmp/last_check')
    
    def calculate_epoch_time_estimate(self, current_iteration, total_iterations, elapsed_time):
        """è®¡ç®—å®Œæˆepochçš„é¢„ä¼°æ—¶é—´"""
        if current_iteration > 0:
            time_per_iteration = elapsed_time / current_iteration
            remaining_iterations = total_iterations - current_iteration
            remaining_time = remaining_iterations * time_per_iteration
            return remaining_time
        return None
    
    def monitor_continuously(self):
        """æŒç»­ç›‘æ§"""
        print("ğŸš€ å¯åŠ¨å®Œæ•´è®­ç»ƒç›‘æ§ç³»ç»Ÿ")
        print("=" * 80)
        print(f"ç›‘æ§å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("ç›‘æ§å†…å®¹: è®­ç»ƒè¿›åº¦ã€GPUçŠ¶æ€ã€å†…å­˜ä½¿ç”¨ã€ç›¸å…³æ€§æŠ¥å‘Š")
        print("=" * 80)
        
        while True:
            current_time = time.time()
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            print(f"\\n[{timestamp}] ç³»ç»ŸçŠ¶æ€æ£€æŸ¥")
            print("-" * 60)
            
            # æ£€æŸ¥è®­ç»ƒè¿›ç¨‹
            training_status = self.get_training_status()
            if training_status:
                print("âœ… è®­ç»ƒè¿›ç¨‹è¿è¡Œä¸­")
                # æå–CPUå’Œå†…å­˜ä½¿ç”¨ä¿¡æ¯
                if '%' in training_status:
                    cpu_match = re.search(r'(\\d+\\.?\\d*)\\s*(?:%|CPU)', training_status)
                    mem_match = re.search(r'(\\d+\\.?\\d*)\\s*(?:GB|MB)', training_status)
                    if cpu_match:
                        print(f"   CPUä½¿ç”¨: {cpu_match.group(1)}%")
                    if mem_match:
                        print(f"   å†…å­˜ä½¿ç”¨: {mem_match.group(1)}")
            else:
                print("âŒ è®­ç»ƒè¿›ç¨‹æœªè¿è¡Œ")
            
            # æ£€æŸ¥GPUçŠ¶æ€
            gpu_info = self.get_gpu_status()
            if gpu_info:
                print("\\nğŸ“Š GPUçŠ¶æ€:")
                for gpu in gpu_info:
                    mem_percent = (gpu['mem_used'] / gpu['mem_total']) * 100
                    print(f"   GPU {gpu['id']}: {gpu['mem_used']}MB/{gpu['mem_total']}MB ({mem_percent:.1f}%) "
                          f"åˆ©ç”¨ç‡{gpu['utilization']}% æ¸©åº¦{gpu['temperature']}Â°C")
            
            # æ£€æŸ¥è®­ç»ƒæ—¥å¿—å’Œè¿›åº¦
            log_text = self.get_training_log(30)
            if log_text:
                print("\\nğŸ“ˆ è®­ç»ƒè¿›åº¦:")
                
                # æå–epochä¿¡æ¯
                epoch_info = self.extract_epoch_progress(log_text)
                if epoch_info:
                    if len(epoch_info) >= 3:
                        epoch = epoch_info[0]
                        if len(epoch_info) == 4:  # åŒ…å«è¿­ä»£ä¿¡æ¯
                            iterations = epoch_info[1]
                            elapsed = epoch_info[2]
                            time_per_it = epoch_info[3]
                            print(f"   å½“å‰Epoch: {epoch}")
                            print(f"   å®Œæˆè¿­ä»£: {iterations}")
                            print(f"   å·²ç”¨æ—¶é—´: {elapsed}")
                            print(f"   æ¯æ¬¡è¿­ä»£: {time_per_it}")
                        else:  # epochå®Œæˆä¿¡æ¯
                            elapsed = epoch_info[1]
                            print(f"   Epoch {epoch} å·²å®Œæˆï¼Œç”¨æ—¶: {elapsed}")
                            self.epoch_times.append(elapsed)
                
                # æ£€æŸ¥é”™è¯¯ä¿¡æ¯
                if 'CUDA out of memory' in log_text:
                    print("   âš ï¸  æ£€æµ‹åˆ°CUDAå†…å­˜ä¸è¶³")
                if 'ERROR' in log_text:
                    error_lines = [line for line in log_text.split('\\n') if 'ERROR' in line]
                    if error_lines:
                        print(f"   âš ï¸  æœ€æ–°é”™è¯¯: {error_lines[-1][:100]}...")
                
                # æ˜¾ç¤ºæœ€æ–°çš„å‡ è¡Œæ—¥å¿—
                recent_lines = log_text.split('\\n')[-3:]
                for line in recent_lines:
                    if line.strip() and not line.startswith('ERROR'):
                        print(f"   ğŸ“ {line[:80]}...")
            
            # æ¯2å°æ—¶æ£€æŸ¥ç›¸å…³æ€§æŠ¥å‘Š
            if current_time - self.last_correlation_check >= 7200:
                print("\\nğŸ” æ£€æŸ¥ç›¸å…³æ€§æŠ¥å‘Š...")
                self.check_correlations()
                self.last_correlation_check = current_time
            
            # æ˜¾ç¤ºè¿è¡Œæ—¶é—´ç»Ÿè®¡
            total_runtime = current_time - self.start_time
            hours = int(total_runtime // 3600)
            minutes = int((total_runtime % 3600) // 60)
            print(f"\\nâ±ï¸  æ€»è¿è¡Œæ—¶é—´: {hours}å°æ—¶{minutes}åˆ†é’Ÿ")
            
            if self.epoch_times:
                print(f"   å·²å®ŒæˆEpochæ•°: {len(self.epoch_times)}")
                avg_epoch_time = sum([self._parse_time(t) for t in self.epoch_times]) / len(self.epoch_times)
                print(f"   å¹³å‡Epochæ—¶é—´: {avg_epoch_time:.1f}ç§’")
            
            print("=" * 80)
            
            # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
            time.sleep(60)
    
    def _parse_time(self, time_str):
        """è§£ææ—¶é—´å­—ç¬¦ä¸²ä¸ºç§’æ•°"""
        try:
            if ':' in time_str:
                parts = time_str.split(':')
                if len(parts) == 2:
                    return int(parts[0]) * 60 + int(parts[1])
                elif len(parts) == 3:
                    return int(parts[0]) * 3600 + int(parts[1]) * 60 + int(parts[2])
            return float(time_str.replace('s', ''))
        except:
            return 0

if __name__ == "__main__":
    monitor = TrainingMonitor()
    try:
        monitor.monitor_continuously()
    except KeyboardInterrupt:
        print("\\n\\nğŸ‘‹ ç›‘æ§ç³»ç»Ÿåœæ­¢")
    except Exception as e:
        print(f"\\nâŒ ç›‘æ§ç³»ç»Ÿé”™è¯¯: {e}")
'''
    return monitoring_script

def create_robust_launcher():
    """åˆ›å»ºç¨³å¥çš„å¯åŠ¨è„šæœ¬"""
    launcher_script = '''#!/bin/bash
# ç¨³å¥çš„è®­ç»ƒå¯åŠ¨è„šæœ¬

echo "ğŸš€ å¯åŠ¨2018å¹´å‰10ä¸ªæœˆæ•°æ®è®­ç»ƒç³»ç»Ÿ"
echo "=================================="

# è®¾ç½®ç¯å¢ƒå˜é‡
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True,max_split_size_mb:256
export CUDA_LAUNCH_BLOCKING=0
export PYTHONUNBUFFERED=1

cd /nas/factor_forecasting

# æ¸…ç†æ—§è¿›ç¨‹
echo "æ¸…ç†æ—§è¿›ç¨‹..."
pkill -f unified_complete_training 2>/dev/null || true
sleep 3

# æ¸…ç†GPUå†…å­˜
echo "é‡ç½®GPUçŠ¶æ€..."
nvidia-smi --gpu-reset-ecc=0,1,2,3 2>/dev/null || true
sleep 2

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source venv/bin/activate

# éªŒè¯é…ç½®æ–‡ä»¶
if [ ! -f "config_2018_10months.yaml" ]; then
    echo "âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨"
    exit 1
fi

echo "âœ… é…ç½®æ–‡ä»¶éªŒè¯é€šè¿‡"

# å¯åŠ¨è®­ç»ƒ
echo "å¯åŠ¨è®­ç»ƒè¿›ç¨‹..."
nohup python unified_complete_training_v2_fixed.py --config config_2018_10months.yaml > training_2018_10months.log 2>&1 &

TRAIN_PID=$!
echo "âœ… è®­ç»ƒå·²å¯åŠ¨ï¼ŒPID: $TRAIN_PID"

# ç­‰å¾…å‡ ç§’ç¡®è®¤å¯åŠ¨
sleep 10

# æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ
if ps -p $TRAIN_PID > /dev/null; then
    echo "âœ… è®­ç»ƒè¿›ç¨‹è¿è¡Œæ­£å¸¸"
    echo "æ—¥å¿—æ–‡ä»¶: training_2018_10months.log"
    echo "å¼€å§‹ç›‘æ§..."
else
    echo "âŒ è®­ç»ƒè¿›ç¨‹å¯åŠ¨å¤±è´¥"
    echo "æŸ¥çœ‹æ—¥å¿—:"
    tail -20 training_2018_10months.log
    exit 1
fi
'''
    return launcher_script

def deploy_complete_solution():
    """éƒ¨ç½²å®Œæ•´è§£å†³æ–¹æ¡ˆ"""
    print("ğŸ”§ éƒ¨ç½²å®Œæ•´è§£å†³æ–¹æ¡ˆ...")
    
    # 1. åˆ›å»ºé…ç½®æ–‡ä»¶
    config = create_optimized_config_2018()
    
    # 2. åˆ›å»ºç›‘æ§ç³»ç»Ÿ
    monitor = create_monitoring_system()
    
    # 3. åˆ›å»ºå¯åŠ¨è„šæœ¬
    launcher = create_robust_launcher()
    
    return config, monitor, launcher

if __name__ == "__main__":
    config, monitor, launcher = deploy_complete_solution()
    print("âœ… å®Œæ•´è§£å†³æ–¹æ¡ˆå·²å‡†å¤‡å°±ç»ª")
    print("åŒ…å«:")
    print("- 2018å¹´å‰10ä¸ªæœˆæ•°æ®è®­ç»ƒé…ç½®")
    print("- å®Œæ•´ç›‘æ§ç³»ç»Ÿ")
    print("- ç¨³å¥å¯åŠ¨è„šæœ¬")
