#!/usr/bin/env python3
"""
Correlationæå–å™¨ - ä»è®­ç»ƒç»“æœä¸­æå–å„targetçš„correlation
"""
import subprocess
import json
import re
import time
from datetime import datetime

def run_ssh_command(cmd: str) -> str:
    """æ‰§è¡ŒSSHå‘½ä»¤"""
    ssh_cmd = [
        'sshpass', '-p', 'Abab1234',
        'ssh', '-o', 'StrictHostKeyChecking=no',
        '-o', 'UserKnownHostsFile=/dev/null', 
        '-o', 'PreferredAuthentications=password',
        '-o', 'PubkeyAuthentication=no',
        'ecs-user@47.120.46.105',
        cmd
    ]
    
    try:
        result = subprocess.run(ssh_cmd, capture_output=True, text=True, timeout=30)
        return result.stdout.strip()
    except Exception as e:
        return f"Error: {e}"

def check_epoch_completion():
    """æ£€æŸ¥epochæ˜¯å¦å®Œæˆ"""
    # æ£€æŸ¥æ˜¯å¦æœ‰éªŒè¯é˜¶æ®µå¼€å§‹
    cmd = '''cd /nas/factor_forecasting && L=$(ls -t logs/*run*.log | head -1) && 
    grep -E "(Validation|validation|Epoch 1|éªŒè¯)" "$L" | tail -5'''
    result = run_ssh_command(cmd)
    
    # æ£€æŸ¥iterationæ•°é‡æ˜¯å¦åœæ­¢å¢é•¿
    cmd2 = '''cd /nas/factor_forecasting && L=$(ls -t logs/*run*.log | head -1) && 
    tail -n 1 "$L" | grep -o "Epoch 0.*: [0-9]*it"'''
    current_iter = run_ssh_command(cmd2)
    
    return result, current_iter

def extract_loss_trend():
    """æå–æŸå¤±è¶‹åŠ¿ï¼Œåˆ¤æ–­æ˜¯å¦æ”¶æ•›"""
    cmd = '''cd /nas/factor_forecasting && L=$(ls -t logs/*run*.log | head -1) && 
    grep -o "Loss=[0-9.]*" "$L" | tail -20 | cut -d= -f2'''
    result = run_ssh_command(cmd)
    
    if result and "Error" not in result:
        losses = [float(x) for x in result.split('\n') if x.strip()]
        return losses
    return []

def compute_correlation_from_logs():
    """å°è¯•ä»æ—¥å¿—ä¸­è®¡ç®—correlationï¼ˆå¦‚æœæœ‰é¢„æµ‹è¾“å‡ºï¼‰"""
    # æœç´¢ä»»ä½•correlationç›¸å…³çš„æ•°å€¼è¾“å‡º
    cmd = '''cd /nas/factor_forecasting && L=$(ls -t logs/*run*.log | head -1) && 
    grep -i -E "(corr[^u]|IC[^C]|pearson|spearman)" "$L" | grep -v "type.*correlation" | grep -E "[0-9]"'''
    result = run_ssh_command(cmd)
    return result

def get_training_statistics():
    """è·å–è®­ç»ƒç»Ÿè®¡ä¿¡æ¯"""
    cmd = '''cd /nas/factor_forecasting && L=$(ls -t logs/*run*.log | head -1) && 
    echo "=== è®­ç»ƒæ—¶é•¿ ===" &&
    echo "å¼€å§‹æ—¶é—´: $(head -20 "$L" | grep -E "[0-9]{2}:[0-9]{2}:[0-9]{2}" | head -1)" &&
    echo "å½“å‰æ—¶é—´: $(date)" &&
    echo "=== iterationç»Ÿè®¡ ===" &&
    LATEST_ITER=$(tail -n 1 "$L" | grep -o "[0-9]*it" | head -1 | sed "s/it//") &&
    echo "å½“å‰iteration: $LATEST_ITER" &&
    echo "=== æŸå¤±ç»Ÿè®¡ ===" &&
    LATEST_LOSS=$(tail -n 1 "$L" | grep -o "Loss=[0-9.]*" | cut -d= -f2) &&
    LATEST_AVG=$(tail -n 1 "$L" | grep -o "Avg=[0-9.]*" | cut -d= -f2) &&
    echo "å½“å‰Loss: $LATEST_LOSS" &&
    echo "å¹³å‡Loss: $LATEST_AVG"'''
    
    return run_ssh_command(cmd)

def estimate_completion_time():
    """ä¼°ç®—å®Œæˆæ—¶é—´"""
    cmd = '''cd /nas/factor_forecasting && L=$(ls -t logs/*run*.log | head -1) && 
    LATEST_ITER=$(tail -n 1 "$L" | grep -o "[0-9]*it" | head -1 | sed "s/it//") &&
    TIME_PER_ITER=$(tail -n 1 "$L" | grep -o "[0-9.]*s/it" | cut -d"s" -f1) &&
    echo "$LATEST_ITER,$TIME_PER_ITER"'''
    
    result = run_ssh_command(cmd)
    if result and "," in result:
        try:
            iter_count, time_per_iter = result.split(',')
            current_iter = int(iter_count)
            time_per = float(time_per_iter)
            
            # åŸºäºæ•°æ®é‡ä¼°ç®—æ€»iterationæ•°
            estimated_total = 4200  # åŸºäº299ä¸ªæ–‡ä»¶å’Œbatch sizeçš„ä¼°ç®—
            remaining = max(0, estimated_total - current_iter)
            remaining_time = remaining * time_per / 60  # åˆ†é’Ÿ
            
            return current_iter, estimated_total, remaining_time
        except:
            pass
    
    return None, None, None

def monitor_and_extract():
    """ä¸»å‡½æ•°ï¼šç›‘æ§å¹¶æå–correlation"""
    print("ğŸ” å¼€å§‹ç›‘æ§Epoch 0å®ŒæˆçŠ¶æ€å¹¶æå–correlation...")
    print("=" * 70)
    
    last_check_time = 0
    check_interval = 60  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
    
    while True:
        try:
            current_time = time.time()
            
            if current_time - last_check_time >= check_interval:
                timestamp = datetime.now().strftime("%H:%M:%S")
                print(f"\n[{timestamp}] ğŸ“Š è®­ç»ƒçŠ¶æ€æ£€æŸ¥")
                print("-" * 50)
                
                # è·å–è®­ç»ƒç»Ÿè®¡
                stats = get_training_statistics()
                if stats:
                    print(stats)
                
                # ä¼°ç®—å®Œæˆæ—¶é—´
                current_iter, total_iter, remaining_min = estimate_completion_time()
                if current_iter and total_iter:
                    progress = (current_iter / total_iter) * 100
                    print(f"\nğŸ“ˆ è¿›åº¦: {current_iter}/{total_iter} ({progress:.1f}%)")
                    if remaining_min:
                        print(f"â±ï¸ é¢„è®¡å‰©ä½™: {remaining_min:.1f} åˆ†é’Ÿ")
                
                # æ£€æŸ¥epochå®Œæˆ
                validation_info, iter_info = check_epoch_completion()
                if validation_info and len(validation_info.strip()) > 0:
                    print(f"\nğŸ‰ æ£€æµ‹åˆ°éªŒè¯é˜¶æ®µæˆ–Epochå®Œæˆ!")
                    print(f"éªŒè¯ä¿¡æ¯: {validation_info}")
                    break
                
                # æ£€æŸ¥correlationè¾“å‡º
                corr_info = compute_correlation_from_logs()
                if corr_info and len(corr_info.strip()) > 0:
                    print(f"\nğŸ“Š å‘ç°correlationä¿¡æ¯:")
                    print(corr_info)
                
                # æ£€æŸ¥æ˜¯å¦æ¥è¿‘å®Œæˆï¼ˆåŸºäºiterationæ•°ï¼‰
                if current_iter and current_iter >= 4000:
                    print(f"\nâš ï¸ æ¥è¿‘é¢„æœŸå®Œæˆç‚¹ (iteration {current_iter})")
                    print("ç»§ç»­ç›‘æ§verificationé˜¶æ®µ...")
                
                last_check_time = current_time
                print("=" * 50)
            
            time.sleep(15)  # çŸ­é—´éš”è½®è¯¢
            
        except KeyboardInterrupt:
            print("\nğŸ›‘ ç›‘æ§ä¸­æ–­")
            break
        except Exception as e:
            print(f"âŒ ç›‘æ§é”™è¯¯: {e}")
            time.sleep(30)
    
    # Epochå®Œæˆåçš„è¯¦ç»†åˆ†æ
    print("\n" + "=" * 70)
    print("ğŸ“Š Epoch 0 è®­ç»ƒå®Œæˆåˆ†æ")
    print("=" * 70)
    
    # æœ€ç»ˆæŸå¤±è¶‹åŠ¿
    losses = extract_loss_trend()
    if losses:
        print(f"\nğŸ“‰ æŸå¤±æ”¶æ•›åˆ†æ:")
        print(f"æœ€æ—©æŸå¤±: {losses[0]:.6f}")
        print(f"æœ€ç»ˆæŸå¤±: {losses[-1]:.6f}")
        print(f"æ”¶æ•›å¹…åº¦: {((losses[0] - losses[-1]) / losses[0] * 100):.1f}%")
        
        # è®¡ç®—æ”¶æ•›ç¨³å®šæ€§
        recent_losses = losses[-5:]
        if len(recent_losses) >= 5:
            volatility = sum(abs(recent_losses[i] - recent_losses[i-1]) for i in range(1, len(recent_losses))) / len(recent_losses)
            print(f"æœ€è¿‘ç¨³å®šæ€§: {volatility:.6f} (è¶Šå°è¶Šç¨³å®š)")
    
    # æ£€æŸ¥æœ€ç»ˆcorrelationç»“æœ
    final_correlation = compute_correlation_from_logs()
    if final_correlation:
        print(f"\nğŸ“ˆ Correlationç»“æœ:")
        print(final_correlation)
    else:
        print("\nâŒ æœªå‘ç°ç›´æ¥çš„correlationè¾“å‡º")
        print("ğŸ’¡ æ£€æŸ¥æ˜¯å¦éœ€è¦è¿è¡ŒéªŒè¯é˜¶æ®µæ¥è®¡ç®—correlation...")
    
    # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
    output_check = run_ssh_command('find /nas/factor_forecasting/outputs/ -name "*.json" -o -name "*.csv" -mmin -30 | head -5')
    if output_check:
        print(f"\nğŸ“ æœ€æ–°è¾“å‡ºæ–‡ä»¶:")
        print(output_check)
    
    print("\nğŸ ç›‘æ§åˆ†æå®Œæˆ!")

if __name__ == "__main__":
    monitor_and_extract()
