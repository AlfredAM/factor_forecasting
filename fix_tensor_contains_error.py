#!/usr/bin/env python3
"""
å½»åº•ä¿®å¤Tensor.__contains__é”™è¯¯
é—®é¢˜æ ¹æºï¼šåœ¨æŸå¤±å‡½æ•°ä¸­ä½¿ç”¨å­—ç¬¦ä¸²æ£€æŸ¥tensorå¯¹è±¡
"""

import os
import re
from pathlib import Path

def fix_tensor_contains_error():
    """ä¿®å¤æ‰€æœ‰å¯èƒ½çš„tensor.__contains__é”™è¯¯"""
    
    fixes_applied = []
    
    # 1. ä¿®å¤ quantitative_loss.py ä¸­çš„é—®é¢˜
    loss_file = Path("src/training/quantitative_loss.py")
    if loss_file.exists():
        with open(loss_file, 'r') as f:
            content = f.read()
        
        # ä¿®å¤ç¬¬77è¡Œçš„é—®é¢˜ï¼šæ£€æŸ¥targetsæ˜¯å¦ä¸ºå­—å…¸
        old_pattern = r'if target_name in predictions and target_name in targets:'
        new_pattern = 'if target_name in predictions and (isinstance(targets, dict) and target_name in targets):'
        
        if old_pattern in content:
            content = content.replace(old_pattern, new_pattern)
            fixes_applied.append("ä¿®å¤quantitative_loss.pyä¸­çš„tensor.__contains__é—®é¢˜")
        
        # ç¡®ä¿æ‰€æœ‰ç±»ä¼¼çš„æ£€æŸ¥éƒ½è¢«ä¿®å¤
        content = re.sub(
            r'(\w+)\s+in\s+(targets)(?!\s*\.)',
            r'(isinstance(\2, dict) and \1 in \2)',
            content
        )
        
        with open(loss_file, 'w') as f:
            f.write(content)
        
        fixes_applied.append(f"æ›´æ–°äº†{loss_file}")
    
    # 2. ä¿®å¤ trainer.py ä¸­çš„ç±»ä¼¼é—®é¢˜
    trainer_file = Path("src/training/trainer.py")
    if trainer_file.exists():
        with open(trainer_file, 'r') as f:
            content = f.read()
        
        # ä¿®å¤CorrelationLossä¸­çš„é—®é¢˜
        old_pattern = r'if target_name in predictions and target_name in targets:'
        new_pattern = 'if target_name in predictions and (isinstance(targets, dict) and target_name in targets):'
        
        if old_pattern in content:
            content = content.replace(old_pattern, new_pattern)
            fixes_applied.append("ä¿®å¤trainer.pyä¸­çš„tensor.__contains__é—®é¢˜")
        
        with open(trainer_file, 'w') as f:
            f.write(content)
        
        fixes_applied.append(f"æ›´æ–°äº†{trainer_file}")
    
    # 3. ä¿®å¤å…¶ä»–å¯èƒ½çš„æ–‡ä»¶
    for file_path in Path("src").rglob("*.py"):
        try:
            with open(file_path, 'r') as f:
                content = f.read()
            
            original_content = content
            
            # æŸ¥æ‰¾å¹¶ä¿®å¤æ‰€æœ‰å¯èƒ½çš„tensor.__contains__é—®é¢˜
            patterns_to_fix = [
                (r'if\s+(\w+)\s+in\s+(targets)(?!\s*\.)', r'if isinstance(\2, dict) and \1 in \2'),
                (r'(\w+)\s+in\s+(predictions)(?!\s*\.)(?!\s*and)', r'(isinstance(\2, dict) and \1 in \2)'),
                (r'if\s+(\w+)\s+in\s+(batch\[.*?\])(?!\s*\.)', r'if isinstance(\2, dict) and \1 in \2'),
            ]
            
            for old_pattern, new_pattern in patterns_to_fix:
                content = re.sub(old_pattern, new_pattern, content)
            
            if content != original_content:
                with open(file_path, 'w') as f:
                    f.write(content)
                fixes_applied.append(f"ä¿®å¤äº†{file_path}ä¸­çš„æ½œåœ¨tensor.__contains__é—®é¢˜")
                
        except Exception as e:
            print(f"å¤„ç†æ–‡ä»¶{file_path}æ—¶å‡ºé”™: {e}")
            continue
    
    # 4. ç‰¹åˆ«å¤„ç†unified_complete_training_v2_fixed.pyä¸­çš„æ•°æ®å¤„ç†
    main_file = Path("src/unified_complete_training_v2_fixed.py")
    if main_file.exists():
        with open(main_file, 'r') as f:
            content = f.read()
        
        # ç¡®ä¿targetså¤„ç†æ­£ç¡®
        target_processing_fix = '''
                # Normalize target shapes to (batch,) when possible
                if isinstance(targets, dict):
                    normalized_targets = {}
                    for t_name, t_val in targets.items():
                        if t_val.dim() == 3 and t_val.size(-1) == 1:
                            t_val = t_val.squeeze(-1)
                        if t_val.dim() == 2:
                            # take last horizon step
                            t_val = t_val[:, -1]
                        normalized_targets[t_name] = t_val
                    targets = normalized_targets
                elif isinstance(targets, torch.Tensor):
                    # å¦‚æœtargetsæ˜¯tensorï¼Œè½¬æ¢ä¸ºå­—å…¸æ ¼å¼
                    target_cols = self.config.get('target_columns', ['intra30m', 'nextT1d', 'ema1d'])
                    if targets.dim() == 2 and targets.size(1) == len(target_cols):
                        targets = {col: targets[:, i] for i, col in enumerate(target_cols)}
                    elif targets.dim() == 1:
                        # å‡è®¾åªæœ‰ä¸€ä¸ªç›®æ ‡
                        targets = {target_cols[0]: targets}
'''
        
        # æ›¿æ¢ç›®æ ‡å¤„ç†éƒ¨åˆ†
        old_target_processing = r'# Normalize target shapes to (batch,) when possible\s*if isinstance\(targets, dict\):.*?targets = normalized_targets'
        content = re.sub(old_target_processing, target_processing_fix.strip(), content, flags=re.DOTALL)
        
        with open(main_file, 'w') as f:
            f.write(content)
        
        fixes_applied.append("ä¿®å¤äº†unified_complete_training_v2_fixed.pyä¸­çš„targetså¤„ç†")
    
    # 5. åˆ›å»ºä¸€ä¸ªä¸“é—¨çš„ç±»å‹æ£€æŸ¥å‡½æ•°
    utils_file = Path("src/utils/tensor_utils.py")
    utils_file.parent.mkdir(parents=True, exist_ok=True)
    
    utils_content = '''#!/usr/bin/env python3
"""
Tensorå·¥å…·å‡½æ•°ï¼Œé¿å…__contains__é”™è¯¯
"""

import torch
from typing import Dict, Union, Any

def safe_dict_check(key: str, container: Union[Dict, torch.Tensor, Any]) -> bool:
    """
    å®‰å…¨åœ°æ£€æŸ¥keyæ˜¯å¦åœ¨containerä¸­ï¼Œé¿å…tensor.__contains__é”™è¯¯
    
    Args:
        key: è¦æ£€æŸ¥çš„é”®
        container: å®¹å™¨å¯¹è±¡
        
    Returns:
        bool: å¦‚æœkeyåœ¨containerä¸­è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
    """
    if isinstance(container, dict):
        return key in container
    elif isinstance(container, torch.Tensor):
        return False  # tensorä¸åº”è¯¥ç”¨äºkeyæ£€æŸ¥
    elif hasattr(container, '__contains__') and not isinstance(container, torch.Tensor):
        try:
            return key in container
        except (TypeError, RuntimeError):
            return False
    else:
        return False

def ensure_targets_dict(targets: Union[torch.Tensor, Dict[str, torch.Tensor]], 
                       target_columns: list) -> Dict[str, torch.Tensor]:
    """
    ç¡®ä¿targetsæ˜¯å­—å…¸æ ¼å¼
    
    Args:
        targets: ç›®æ ‡å€¼ï¼Œå¯èƒ½æ˜¯tensoræˆ–å­—å…¸
        target_columns: ç›®æ ‡åˆ—ååˆ—è¡¨
        
    Returns:
        Dict[str, torch.Tensor]: å­—å…¸æ ¼å¼çš„ç›®æ ‡å€¼
    """
    if isinstance(targets, dict):
        return targets
    elif isinstance(targets, torch.Tensor):
        if targets.dim() == 2 and targets.size(1) == len(target_columns):
            return {col: targets[:, i] for i, col in enumerate(target_columns)}
        elif targets.dim() == 1:
            # å‡è®¾åªæœ‰ä¸€ä¸ªç›®æ ‡
            return {target_columns[0]: targets}
        else:
            # é»˜è®¤å¤„ç†
            return {target_columns[0]: targets.flatten()}
    else:
        raise TypeError(f"ä¸æ”¯æŒçš„targetsç±»å‹: {type(targets)}")
'''
    
    with open(utils_file, 'w') as f:
        f.write(utils_content)
    
    fixes_applied.append(f"åˆ›å»ºäº†{utils_file}å·¥å…·å‡½æ•°")
    
    return fixes_applied

if __name__ == "__main__":
    print("ğŸ”§ å¼€å§‹ä¿®å¤Tensor.__contains__é”™è¯¯...")
    
    fixes = fix_tensor_contains_error()
    
    print("âœ… ä¿®å¤å®Œæˆï¼")
    print("åº”ç”¨çš„ä¿®å¤:")
    for fix in fixes:
        print(f"  - {fix}")
    
    print("\nğŸ¯ ä¿®å¤è¯´æ˜:")
    print("1. ä¿®å¤äº†æŸå¤±å‡½æ•°ä¸­çš„å­—ç¬¦ä¸²ä¸tensoræ¯”è¾ƒé—®é¢˜")
    print("2. ç¡®ä¿æ‰€æœ‰targetséƒ½æ­£ç¡®è½¬æ¢ä¸ºå­—å…¸æ ¼å¼")
    print("3. æ·»åŠ äº†ç±»å‹æ£€æŸ¥ä»¥é¿å…ç±»ä¼¼é”™è¯¯")
    print("4. åˆ›å»ºäº†å®‰å…¨çš„å·¥å…·å‡½æ•°")
