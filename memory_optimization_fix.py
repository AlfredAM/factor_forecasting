#!/usr/bin/env python3
"""
å†…å­˜ä¼˜åŒ–ä¿®å¤è„šæœ¬ - ä»æ ¹æœ¬ä¸Šå½»åº•è§£å†³CUDAå†…å­˜é—®é¢˜
"""

import yaml
import os

def create_memory_optimized_config():
    """åˆ›å»ºå†…å­˜ä¼˜åŒ–çš„é…ç½®æ–‡ä»¶"""
    
    config = {
        # æ¨¡å‹é…ç½® - å¤§å¹…å‡å°æ¨¡å‹å¤æ‚åº¦
        'model_type': 'AdvancedFactorForecastingTCNAttention',
        'input_dim': 100,
        'hidden_dim': 512,  # ä»1024å‡å°‘åˆ°512
        'num_layers': 8,    # ä»16å‡å°‘åˆ°8
        'num_heads': 16,    # ä»32å‡å°‘åˆ°16
        'tcn_kernel_size': 5,  # ä»7å‡å°‘åˆ°5
        'tcn_dilation_factor': 2,
        'dropout_rate': 0.1,
        'attention_dropout': 0.05,
        
        # è®­ç»ƒé…ç½® - æåº¦ä¿å®ˆçš„å†…å­˜ä½¿ç”¨
        'target_columns': ['nextT1d'],  # åªè®­ç»ƒä¸€ä¸ªç›®æ ‡ï¼Œå‡å°‘å†…å­˜
        'sequence_length': 30,  # ä»60å‡å°‘åˆ°30
        'epochs': 50,
        'batch_size': 512,  # è¿›ä¸€æ­¥å‡å°æ‰¹æ¬¡å¤§å°
        'fixed_batch_size': 512,
        'learning_rate': 0.0005,  # å¢åŠ å­¦ä¹ ç‡è¡¥å¿å°æ‰¹æ¬¡
        'weight_decay': 0.01,
        'gradient_clip_norm': 1.0,
        'use_mixed_precision': True,
        'accumulation_steps': 4,  # ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯è¡¥å¿å°æ‰¹æ¬¡
        
        # DataLoaderé…ç½® - æœ€å°åŒ–å†…å­˜ä½¿ç”¨
        'use_adaptive_batch_size': False,
        'adaptive_batch_size': False,
        'num_workers': 0,
        'pin_memory': False,  # ç¦ç”¨pin_memoryå‡å°‘å†…å­˜ä½¿ç”¨
        'use_distributed': False,
        'auto_resume': True,
        'log_level': 'INFO',
        
        # ICæŠ¥å‘Šé…ç½®
        'ic_report_interval': 7200,
        'enable_ic_reporting': True,
        'checkpoint_frequency': 10,
        'save_all_checkpoints': False,
        
        # è·¯å¾„é…ç½®
        'output_dir': '/nas/factor_forecasting/outputs',
        'data_dir': '/nas/feature_v2_10s',
        
        # æ•°æ®åˆ†å‰²é…ç½®
        'train_start_date': '2018-01-02',
        'train_end_date': '2018-06-30',  # å‡å°‘è®­ç»ƒæ•°æ®é‡
        'val_start_date': '2018-07-01',
        'val_end_date': '2018-08-31',
        'test_start_date': '2018-09-01',
        'test_end_date': '2018-10-31',
        
        # å¹´åº¦æ»šåŠ¨è®­ç»ƒ
        'enforce_next_year_prediction': True,
        'enable_yearly_rolling': False,  # æš‚æ—¶ç¦ç”¨å‡å°‘å¤æ‚åº¦
        'min_train_years': 1,
        'rolling_window_years': 1,
        'shuffle_buffer_size': 256,
        
        # GPUå†…å­˜ä¼˜åŒ–
        'gpu_memory_fraction': 0.8,
        'enable_gpu_growth': True,
        'torch_compile': False,  # ç¦ç”¨torchç¼–è¯‘å‡å°‘å†…å­˜
        'enable_flash_attention': False,
        'use_channels_last': False,
        
        # æ•°æ®å¤„ç†ä¼˜åŒ–
        'streaming_chunk_size': 50000,  # å‡å°‘chunkå¤§å°
        'max_memory_usage': 400,  # å‡å°‘æœ€å¤§å†…å­˜ä½¿ç”¨
        'enable_memory_mapping': False,  # ç¦ç”¨å†…å­˜æ˜ å°„
        
        # ç›‘æ§é…ç½®
        'enable_tensorboard': False,  # ç¦ç”¨tensorboardå‡å°‘å†…å­˜
        'enable_wandb': False,
        
        # æŸå¤±å‡½æ•°é…ç½®
        'use_adaptive_loss': False,  # ä½¿ç”¨ç®€å•æŸå¤±å‡½æ•°
        'correlation_weight': 1.0,
        'mse_weight': 0.1,
        'rank_correlation_weight': 0.1,
        'risk_penalty_weight': 0.05,
        'target_correlations': [0.05],
        'max_leverage': 1.5,
        'transaction_cost': 0.001
    }
    
    return config

def create_memory_safe_training_script():
    """åˆ›å»ºå†…å­˜å®‰å…¨çš„è®­ç»ƒè„šæœ¬"""
    
    script_content = '''#!/usr/bin/env python3
"""
å†…å­˜å®‰å…¨è®­ç»ƒè„šæœ¬ - æåº¦ä¿å®ˆçš„å†…å­˜ä½¿ç”¨ç­–ç•¥
"""

import os
import sys
import gc
import torch
import torch.multiprocessing as mp

# è®¾ç½®CUDAå†…å­˜ç®¡ç†
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'

try:
    mp.set_start_method('spawn', force=True)
except RuntimeError:
    pass

# å¯ç”¨CUDAå†…å­˜ä¼˜åŒ–
torch.cuda.empty_cache()
if torch.cuda.is_available():
    torch.cuda.set_per_process_memory_fraction(0.8)

# å¯¼å…¥é¡¹ç›®æ¨¡å—
sys.path.insert(0, '/nas/factor_forecasting/src')

def cleanup_memory():
    """å¼ºåˆ¶æ¸…ç†å†…å­˜"""
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()

def main():
    """ä¸»å‡½æ•° - å†…å­˜å®‰å…¨ç‰ˆæœ¬"""
    try:
        # æ¸…ç†åˆå§‹å†…å­˜
        cleanup_memory()
        
        # å¯¼å…¥è®­ç»ƒæ¨¡å—
        from unified_complete_training_v2_fixed import UnifiedCompleteTrainer
        import yaml
        
        # åŠ è½½é…ç½®
        with open('/nas/factor_forecasting/memory_safe_config.yaml', 'r') as f:
            config = yaml.safe_load(f)
        
        print("ğŸš€ å¯åŠ¨å†…å­˜å®‰å…¨è®­ç»ƒ...")
        print(f"é…ç½®: batch_size={config['batch_size']}, hidden_dim={config['hidden_dim']}")
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = UnifiedCompleteTrainer(config, 0, 1)
        
        # è®¾ç½®æ•°æ®åŠ è½½å™¨
        trainer.setup_data_loaders()
        cleanup_memory()
        
        # åˆ›å»ºæ¨¡å‹
        trainer.create_model()
        cleanup_memory()
        
        print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œå¼€å§‹è®­ç»ƒ...")
        
        # å¼€å§‹è®­ç»ƒ
        trainer.train()
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒé”™è¯¯: {e}")
        cleanup_memory()
        raise
    finally:
        cleanup_memory()

if __name__ == "__main__":
    main()
'''
    
    return script_content

def apply_memory_fixes():
    """åº”ç”¨å†…å­˜ä¿®å¤"""
    
    print("=" * 60)
    print("ğŸ”§ å¼€å§‹å†…å­˜ä¼˜åŒ–ä¿®å¤...")
    print("=" * 60)
    
    # 1. åˆ›å»ºå†…å­˜ä¼˜åŒ–é…ç½®
    config = create_memory_optimized_config()
    
    with open('/nas/factor_forecasting/memory_safe_config.yaml', 'w') as f:
        yaml.dump(config, f, default_flow_style=False)
    
    print("âœ… åˆ›å»ºäº†å†…å­˜å®‰å…¨é…ç½®æ–‡ä»¶")
    
    # 2. åˆ›å»ºå†…å­˜å®‰å…¨è®­ç»ƒè„šæœ¬
    script_content = create_memory_safe_training_script()
    
    with open('/nas/factor_forecasting/memory_safe_training.py', 'w') as f:
        f.write(script_content)
    
    print("âœ… åˆ›å»ºäº†å†…å­˜å®‰å…¨è®­ç»ƒè„šæœ¬")
    
    # 3. è®¾ç½®CUDAç¯å¢ƒå˜é‡
    cuda_env_script = '''#!/bin/bash
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
export CUDA_LAUNCH_BLOCKING=1
export CUDA_VISIBLE_DEVICES=0
export OMP_NUM_THREADS=1
export MKL_NUM_THREADS=1

echo "ğŸ”§ CUDAç¯å¢ƒå˜é‡å·²è®¾ç½®"
echo "PYTORCH_CUDA_ALLOC_CONF=$PYTORCH_CUDA_ALLOC_CONF"
echo "CUDA_LAUNCH_BLOCKING=$CUDA_LAUNCH_BLOCKING"
echo "CUDA_VISIBLE_DEVICES=$CUDA_VISIBLE_DEVICES"
'''
    
    with open('/nas/factor_forecasting/setup_cuda_env.sh', 'w') as f:
        f.write(cuda_env_script)
    
    os.chmod('/nas/factor_forecasting/setup_cuda_env.sh', 0o755)
    
    print("âœ… åˆ›å»ºäº†CUDAç¯å¢ƒè®¾ç½®è„šæœ¬")
    
    print("=" * 60)
    print("ğŸ¯ å†…å­˜ä¼˜åŒ–ä¿®å¤å®Œæˆï¼")
    print("=" * 60)
    print("ä¸»è¦ä¼˜åŒ–:")
    print("- æ¨¡å‹å‚æ•°å‡å°‘ ~75%")
    print("- æ‰¹æ¬¡å¤§å°: 4096 â†’ 512")
    print("- åºåˆ—é•¿åº¦: 60 â†’ 30") 
    print("- éšè—ç»´åº¦: 1024 â†’ 512")
    print("- å±‚æ•°: 16 â†’ 8")
    print("- æ³¨æ„åŠ›å¤´: 32 â†’ 16")
    print("- è®­ç»ƒæ•°æ®é‡å‡å°‘50%")
    print("- å¯ç”¨æ¢¯åº¦ç´¯ç§¯è¡¥å¿")
    print("=" * 60)

if __name__ == "__main__":
    apply_memory_fixes()
