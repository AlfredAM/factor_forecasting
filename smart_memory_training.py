#!/usr/bin/env python3
"""
æ™ºèƒ½å†…å­˜ç®¡ç†è®­ç»ƒè„šæœ¬
åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°ï¼Œæœ€å¤§åŒ–ç¡¬ä»¶åˆ©ç”¨ç‡åŒæ—¶é¿å…å†…å­˜æº¢å‡º
"""

import os
import sys
import time
import psutil
import subprocess
from pathlib import Path

def get_gpu_memory_info():
    """è·å–GPUå†…å­˜ä¿¡æ¯"""
    try:
        result = subprocess.run(['nvidia-smi', '--query-gpu=memory.used,memory.total', '--format=csv,noheader,nounits'], 
                              capture_output=True, text=True)
        if result.returncode == 0:
            lines = result.stdout.strip().split('\n')
            gpu_info = []
            for line in lines:
                used, total = map(int, line.split(', '))
                gpu_info.append({'used': used, 'total': total, 'free': total - used})
            return gpu_info
    except Exception as e:
        print(f"è·å–GPUä¿¡æ¯å¤±è´¥: {e}")
    return []

def get_optimal_batch_size():
    """æ ¹æ®å½“å‰å†…å­˜çŠ¶å†µè®¡ç®—æœ€ä¼˜æ‰¹æ¬¡å¤§å°"""
    gpu_info = get_gpu_memory_info()
    if not gpu_info:
        return 512  # ä¿å®ˆé»˜è®¤å€¼
    
    # ä½¿ç”¨ç¬¬ä¸€ä¸ªGPUçš„ä¿¡æ¯
    gpu = gpu_info[0]
    free_memory_gb = gpu['free'] / 1024  # è½¬æ¢ä¸ºGB
    
    # æ ¹æ®å¯ç”¨å†…å­˜åŠ¨æ€è®¡ç®—æ‰¹æ¬¡å¤§å°
    if free_memory_gb > 15:
        return 2048
    elif free_memory_gb > 10:
        return 1024
    elif free_memory_gb > 5:
        return 512
    else:
        return 256

def create_launcher_script():
    """åˆ›å»ºæ™ºèƒ½å¯åŠ¨è„šæœ¬"""
    launcher_content = f'''#!/bin/bash
# æ™ºèƒ½å†…å­˜ç®¡ç†å¯åŠ¨è„šæœ¬

export PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True,max_split_size_mb:256"
export CUDA_LAUNCH_BLOCKING=0
export PYTHONUNBUFFERED=1
export OMP_NUM_THREADS=32  # æœ€å¤§åŒ–CPUåˆ©ç”¨ç‡

cd /nas/factor_forecasting
source venv/bin/activate

# æ¸…ç†æ—§è¿›ç¨‹
pkill -f unified_complete_training 2>/dev/null || true
sleep 3

# æ¸…ç†GPUç¼“å­˜
python -c "import torch; torch.cuda.empty_cache()" 2>/dev/null || true

echo "å¯åŠ¨æ™ºèƒ½å†…å­˜ç®¡ç†è®­ç»ƒ..."
nohup python unified_complete_training_v2_fixed.py --config balanced_high_performance_config.yaml > training_smart_memory.log 2>&1 &

echo "è®­ç»ƒå·²å¯åŠ¨ï¼ŒPID: $!"
echo "ç›‘æ§å‘½ä»¤: tail -f training_smart_memory.log"
'''
    
    return launcher_content

def create_continuous_monitor():
    """åˆ›å»ºæŒç»­ç›‘æ§è„šæœ¬"""
    monitor_content = '''#!/usr/bin/env python3
"""
æŒç»­è®­ç»ƒç›‘æ§å’Œç›¸å…³æ€§æŠ¥å‘Šè„šæœ¬
"""

import subprocess
import time
import re
import json
from datetime import datetime
from pathlib import Path

class TrainingMonitor:
    def __init__(self):
        self.last_correlation_check = 0
        self.epoch_times = []
        
    def get_training_status(self):
        """è·å–è®­ç»ƒçŠ¶æ€"""
        try:
            # æ£€æŸ¥è¿›ç¨‹
            proc_result = subprocess.run([
                'ps', 'aux'
            ], capture_output=True, text=True)
            
            training_process = None
            for line in proc_result.stdout.split('\\n'):
                if 'unified_complete_training' in line and 'grep' not in line:
                    training_process = line.strip()
                    break
            
            return training_process
        except Exception as e:
            return f"æ£€æŸ¥å¤±è´¥: {e}"
    
    def get_gpu_status(self):
        """è·å–GPUçŠ¶æ€"""
        try:
            result = subprocess.run([
                'nvidia-smi', '--query-gpu=index,memory.used,memory.total,utilization.gpu,temperature.gpu',
                '--format=csv,noheader,nounits'
            ], capture_output=True, text=True)
            
            return result.stdout.strip()
        except Exception as e:
            return f"GPUçŠ¶æ€è·å–å¤±è´¥: {e}"
    
    def get_training_log(self):
        """è·å–è®­ç»ƒæ—¥å¿—"""
        try:
            with open('/nas/factor_forecasting/training_smart_memory.log', 'r') as f:
                lines = f.readlines()
                return ''.join(lines[-50:])  # æœ€å50è¡Œ
        except Exception as e:
            return f"æ—¥å¿—è¯»å–å¤±è´¥: {e}"
    
    def extract_epoch_info(self, log_text):
        """æå–epochä¿¡æ¯"""
        # æŸ¥æ‰¾æœ€æ–°çš„epochä¿¡æ¯
        epoch_pattern = r'Epoch (\\d+) Training: (\\d+)it \\[([^,]+), ([^]]+)\\]'
        matches = re.findall(epoch_pattern, log_text)
        
        if matches:
            epoch, iterations, time_elapsed, time_per_it = matches[-1]
            return {
                'epoch': int(epoch),
                'iterations': int(iterations),
                'time_elapsed': time_elapsed,
                'time_per_iteration': time_per_it
            }
        return None
    
    def check_correlations(self):
        """æ£€æŸ¥ç›¸å…³æ€§æŠ¥å‘Š"""
        try:
            output_dir = Path('/nas/factor_forecasting/outputs')
            if output_dir.exists():
                json_files = list(output_dir.glob('**/*.json'))
                if json_files:
                    # è¯»å–æœ€æ–°çš„ç›¸å…³æ€§æŠ¥å‘Š
                    latest_file = max(json_files, key=lambda p: p.stat().st_mtime)
                    with open(latest_file, 'r') as f:
                        data = json.load(f)
                    
                    correlations = {}
                    if 'correlations' in data:
                        for target, corr_data in data['correlations'].items():
                            if 'in_sample_ic' in corr_data:
                                correlations[f'{target}_in_sample'] = corr_data['in_sample_ic']
                            if 'out_sample_ic' in corr_data:
                                correlations[f'{target}_out_sample'] = corr_data['out_sample_ic']
                    
                    return correlations
        except Exception as e:
            print(f"ç›¸å…³æ€§æ£€æŸ¥å¤±è´¥: {e}")
        
        return {}
    
    def monitor(self):
        """ä¸»ç›‘æ§å¾ªç¯"""
        print("ğŸš€ æ™ºèƒ½è®­ç»ƒç›‘æ§ç³»ç»Ÿå¯åŠ¨")
        print("=" * 80)
        
        while True:
            current_time = time.time()
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            print(f"\\n[{timestamp}] ç³»ç»ŸçŠ¶æ€æ£€æŸ¥")
            print("-" * 60)
            
            # æ£€æŸ¥è®­ç»ƒè¿›ç¨‹
            training_status = self.get_training_status()
            if training_status and 'python' in training_status:
                print("âœ… è®­ç»ƒè¿›ç¨‹è¿è¡Œä¸­")
                # æå–CPUå’Œå†…å­˜ä½¿ç”¨ç‡
                parts = training_status.split()
                if len(parts) >= 11:
                    cpu_usage = parts[2]
                    mem_usage = parts[3]
                    print(f"   CPU: {cpu_usage}%, å†…å­˜: {mem_usage}%")
            else:
                print("âŒ è®­ç»ƒè¿›ç¨‹æœªè¿è¡Œ")
            
            # GPUçŠ¶æ€
            gpu_status = self.get_gpu_status()
            print("\\nğŸ“Š GPUçŠ¶æ€:")
            for line in gpu_status.split('\\n'):
                if line.strip():
                    parts = line.split(', ')
                    if len(parts) >= 5:
                        gpu_id, mem_used, mem_total, util, temp = parts
                        mem_percent = (int(mem_used) / int(mem_total)) * 100
                        print(f"   GPU {gpu_id}: {mem_used}MB/{mem_total}MB ({mem_percent:.1f}%), åˆ©ç”¨ç‡: {util}%, æ¸©åº¦: {temp}Â°C")
            
            # è®­ç»ƒè¿›åº¦
            log_text = self.get_training_log()
            epoch_info = self.extract_epoch_info(log_text)
            
            if epoch_info:
                print("\\nğŸ“ˆ è®­ç»ƒè¿›åº¦:")
                print(f"   å½“å‰Epoch: {epoch_info['epoch']}")
                print(f"   å®Œæˆè¿­ä»£: {epoch_info['iterations']}")
                print(f"   å·²ç”¨æ—¶é—´: {epoch_info['time_elapsed']}")
                print(f"   æ¯æ¬¡è¿­ä»£: {epoch_info['time_per_iteration']}")
                
                # ä¼°ç®—epochå®Œæˆæ—¶é—´
                if epoch_info['epoch'] == 0:  # ç¬¬ä¸€ä¸ªepoch
                    time_per_it_seconds = self.parse_time_to_seconds(epoch_info['time_per_iteration'])
                    if time_per_it_seconds and epoch_info['iterations'] > 10:
                        # ä¼°ç®—æ€»è¿­ä»£æ•°ï¼ˆå‡è®¾æ•°æ®é‡å›ºå®šï¼‰
                        estimated_total_iterations = epoch_info['iterations'] * 2  # ç²—ç•¥ä¼°è®¡
                        remaining_iterations = estimated_total_iterations - epoch_info['iterations']
                        estimated_remaining_time = remaining_iterations * time_per_it_seconds
                        print(f"   é¢„è®¡å‰©ä½™æ—¶é—´: {self.seconds_to_time_str(estimated_remaining_time)}")
            
            # æ£€æŸ¥å†…å­˜é”™è¯¯
            if 'CUDA out of memory' in log_text:
                print("\\nâš ï¸  æ£€æµ‹åˆ°CUDAå†…å­˜ä¸è¶³")
            elif 'ERROR' in log_text:
                print("\\nâš ï¸  æ£€æµ‹åˆ°è®­ç»ƒé”™è¯¯")
            
            # æ¯2å°æ—¶æ£€æŸ¥ç›¸å…³æ€§
            if current_time - self.last_correlation_check >= 7200:
                print("\\nğŸ“Š æ£€æŸ¥ç›¸å…³æ€§æŠ¥å‘Š...")
                correlations = self.check_correlations()
                if correlations:
                    print("   æœ€æ–°ç›¸å…³æ€§æ•°æ®:")
                    for target, corr in correlations.items():
                        print(f"     {target}: {corr:.4f}")
                else:
                    print("   æš‚æ— ç›¸å…³æ€§æ•°æ®")
                
                self.last_correlation_check = current_time
            
            print("=" * 80)
            
            # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
            time.sleep(30)
    
    def parse_time_to_seconds(self, time_str):
        """è§£ææ—¶é—´å­—ç¬¦ä¸²ä¸ºç§’æ•°"""
        try:
            if 's/it' in time_str:
                return float(time_str.replace('s/it', ''))
        except:
            pass
        return None
    
    def seconds_to_time_str(self, seconds):
        """è½¬æ¢ç§’æ•°ä¸ºæ—¶é—´å­—ç¬¦ä¸²"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        seconds = int(seconds % 60)
        return f"{hours:02d}:{minutes:02d}:{seconds:02d}"

if __name__ == "__main__":
    monitor = TrainingMonitor()
    try:
        monitor.monitor()
    except KeyboardInterrupt:
        print("\\n\\nğŸ‘‹ ç›‘æ§ç»“æŸ")
'''
    
    return monitor_content

def deploy_smart_training():
    """éƒ¨ç½²æ™ºèƒ½è®­ç»ƒç³»ç»Ÿ"""
    print("ğŸš€ éƒ¨ç½²æ™ºèƒ½å†…å­˜ç®¡ç†è®­ç»ƒç³»ç»Ÿ...")
    
    # åˆ›å»ºå¯åŠ¨è„šæœ¬
    launcher_script = create_launcher_script()
    with open('/tmp/smart_launcher.sh', 'w') as f:
        f.write(launcher_script)
    
    # åˆ›å»ºç›‘æ§è„šæœ¬
    monitor_script = create_continuous_monitor()
    with open('/tmp/smart_monitor.py', 'w') as f:
        f.write(monitor_script)
    
    print("âœ… è„šæœ¬åˆ›å»ºå®Œæˆ")
    return True

if __name__ == "__main__":
    deploy_smart_training()
