#!/usr/bin/env python3
"""
ç»ˆæå†…å­˜ä¼˜åŒ–ä¿®å¤è„šæœ¬
ä»æ ¹æœ¬ä¸Šè§£å†³CUDAå†…å­˜é—®é¢˜ï¼Œç¡®ä¿è®­ç»ƒç¨³å®šè¿è¡Œ
"""

import os
import re
from pathlib import Path

def create_robust_config():
    """åˆ›å»ºæåº¦ä¿å®ˆçš„å†…å­˜é…ç½®"""
    config_content = """# æåº¦ä¿å®ˆçš„å†…å­˜é…ç½® - ç¡®ä¿ç¨³å®šè®­ç»ƒ
model_type: AdvancedFactorForecastingTCNAttention
input_dim: 100
hidden_dim: 512    # å¤§å¹…å‡å°‘éšè—å±‚ç»´åº¦
num_layers: 8      # å‡å°‘å±‚æ•°
num_heads: 8       # å‡å°‘æ³¨æ„åŠ›å¤´æ•°
tcn_kernel_size: 5
tcn_dilation_factor: 2
dropout_rate: 0.1
attention_dropout: 0.05
target_columns: [nextT1d]  # åªé¢„æµ‹ä¸€ä¸ªç›®æ ‡ï¼Œå‡å°‘å†…å­˜
sequence_length: 30        # å‡å°‘åºåˆ—é•¿åº¦
epochs: 200
batch_size: 512           # æå°æ‰¹æ¬¡å¤§å°
fixed_batch_size: 512
learning_rate: 0.0001
weight_decay: 0.01
gradient_clip_norm: 1.0
use_mixed_precision: true
accumulation_steps: 4     # å¢åŠ æ¢¯åº¦ç´¯ç§¯æ­¥æ•°è¡¥å¿å°æ‰¹æ¬¡
use_adaptive_batch_size: false
adaptive_batch_size: false
num_workers: 0
pin_memory: false         # ç¦ç”¨pin_memoryèŠ‚çœå†…å­˜
use_distributed: false
auto_resume: true
log_level: INFO
ic_report_interval: 7200
enable_ic_reporting: true
checkpoint_frequency: 5
save_all_checkpoints: false
output_dir: /nas/factor_forecasting/outputs
data_dir: /nas/feature_v2_10s
train_start_date: 2018-01-02
train_end_date: 2018-02-28    # å‡å°‘è®­ç»ƒæ•°æ®é‡
val_start_date: 2018-03-01
val_end_date: 2018-03-31
test_start_date: 2018-04-01
test_end_date: 2018-04-30
enforce_next_year_prediction: false
enable_yearly_rolling: false
min_train_years: 1
rolling_window_years: 1
shuffle_buffer_size: 128      # æå°ç¼“å†²åŒº

# GPUå†…å­˜ä¼˜åŒ–
gpu_memory_fraction: 0.8
enable_gpu_growth: true
max_memory_usage: 20         # é™åˆ¶æœ€å¤§å†…å­˜ä½¿ç”¨ä¸º20GB
streaming_chunk_size: 1000   # æå°chunkå¤§å°
enable_memory_mapping: false

# PyTorchå†…å­˜ä¼˜åŒ–ç¯å¢ƒå˜é‡
pytorch_cuda_alloc_conf: "expandable_segments:True,max_split_size_mb:128"
"""
    
    with open("/nas/factor_forecasting/ultra_conservative_config.yaml", "w") as f:
        f.write(config_content)
    
    print("âœ… åˆ›å»ºäº†æåº¦ä¿å®ˆçš„å†…å­˜é…ç½®")

def create_memory_optimized_launcher():
    """åˆ›å»ºå†…å­˜ä¼˜åŒ–çš„å¯åŠ¨è„šæœ¬"""
    launcher_content = '''#!/bin/bash
# å†…å­˜ä¼˜åŒ–å¯åŠ¨è„šæœ¬

export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True,max_split_size_mb:128
export CUDA_LAUNCH_BLOCKING=1
export PYTHONUNBUFFERED=1

# æ¸…ç†GPUå†…å­˜
nvidia-smi --gpu-reset

# å¯åŠ¨è®­ç»ƒ
cd /nas/factor_forecasting
source venv/bin/activate

# æ€æ­»æ—§è¿›ç¨‹
pkill -f unified_complete_training 2>/dev/null || true

# ç­‰å¾…GPUå®Œå…¨é‡Šæ”¾
sleep 5

# å¯åŠ¨æ–°è®­ç»ƒ
nohup python unified_complete_training_v2_fixed.py --config ultra_conservative_config.yaml > training_memory_optimized.log 2>&1 &

echo "è®­ç»ƒå·²å¯åŠ¨ï¼ŒPID: $!"
'''
    
    with open("/nas/factor_forecasting/launch_memory_optimized.sh", "w") as f:
        f.write(launcher_content)
    
    print("âœ… åˆ›å»ºäº†å†…å­˜ä¼˜åŒ–å¯åŠ¨è„šæœ¬")

def patch_training_script_for_memory():
    """ä¿®å¤è®­ç»ƒè„šæœ¬ä»¥ä¼˜åŒ–å†…å­˜ä½¿ç”¨"""
    script_path = "/nas/factor_forecasting/unified_complete_training_v2_fixed.py"
    
    with open(script_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æ·»åŠ æ›´æ¿€è¿›çš„å†…å­˜æ¸…ç†
    memory_patch = '''
# æ¿€è¿›å†…å­˜ç®¡ç†è¡¥ä¸
import gc
import torch

def aggressive_memory_cleanup():
    """æ¿€è¿›çš„å†…å­˜æ¸…ç†"""
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
        # å¼ºåˆ¶æ¸…ç†æœªä½¿ç”¨çš„ç¼“å­˜
        torch.cuda.reset_peak_memory_stats()

# åœ¨è®­ç»ƒå¾ªç¯ä¸­æ·»åŠ å†…å­˜æ£€æŸ¥
def check_memory_and_cleanup():
    """æ£€æŸ¥å†…å­˜å¹¶åœ¨å¿…è¦æ—¶æ¸…ç†"""
    if torch.cuda.is_available():
        memory_used = torch.cuda.memory_allocated() / 1024**3  # GB
        memory_reserved = torch.cuda.memory_reserved() / 1024**3  # GB
        
        # å¦‚æœä½¿ç”¨è¶…è¿‡18GBï¼Œå¼ºåˆ¶æ¸…ç†
        if memory_reserved > 18.0:
            aggressive_memory_cleanup()
            return True
    return False
'''
    
    # åœ¨å¯¼å…¥åæ·»åŠ å†…å­˜ç®¡ç†å‡½æ•°
    if 'def aggressive_memory_cleanup' not in content:
        import_end = content.find('# Import components')
        if import_end != -1:
            content = content[:import_end] + memory_patch + '\n' + content[import_end:]
    
    # åœ¨è®­ç»ƒå¾ªç¯ä¸­æ·»åŠ å†…å­˜æ£€æŸ¥
    if 'check_memory_and_cleanup()' not in content:
        # æŸ¥æ‰¾è®­ç»ƒå¾ªç¯
        train_loop_pattern = r'(for batch_idx, batch in enumerate\(progress_bar\):)'
        replacement = r'\1\n            # å†…å­˜æ£€æŸ¥å’Œæ¸…ç†\n            if batch_idx % 10 == 0:  # æ¯10ä¸ªbatchæ£€æŸ¥ä¸€æ¬¡\n                check_memory_and_cleanup()'
        content = re.sub(train_loop_pattern, replacement, content)
    
    with open(script_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print("âœ… è®­ç»ƒè„šæœ¬å·²æ·»åŠ æ¿€è¿›å†…å­˜ç®¡ç†")

def create_monitoring_script():
    """åˆ›å»ºå¢å¼ºçš„ç›‘æ§è„šæœ¬"""
    monitoring_script = '''#!/usr/bin/env python3
import subprocess
import time
import json
from datetime import datetime

def get_detailed_status():
    """è·å–è¯¦ç»†çŠ¶æ€"""
    try:
        # æ£€æŸ¥è¿›ç¨‹
        proc_result = subprocess.run([
            'sshpass', '-p', 'Abab1234', 'ssh', '-o', 'StrictHostKeyChecking=no',
            'ecs-user@8.216.35.79',
            'ps aux | grep "python.*unified_complete_training" | grep -v grep'
        ], capture_output=True, text=True)
        
        # GPUçŠ¶æ€
        gpu_result = subprocess.run([
            'sshpass', '-p', 'Abab1234', 'ssh', '-o', 'StrictHostKeyChecking=no',
            'ecs-user@8.216.35.79',
            'nvidia-smi --query-gpu=memory.used,memory.total,utilization.gpu,temperature.gpu --format=csv,noheader,nounits'
        ], capture_output=True, text=True)
        
        # è®­ç»ƒæ—¥å¿—
        log_result = subprocess.run([
            'sshpass', '-p', 'Abab1234', 'ssh', '-o', 'StrictHostKeyChecking=no',
            'ecs-user@8.216.35.79',
            'cd /nas/factor_forecasting && tail -10 training_memory_optimized.log'
        ], capture_output=True, text=True)
        
        return {
            'process': proc_result.stdout.strip(),
            'gpu': gpu_result.stdout.strip(),
            'log': log_result.stdout.strip(),
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
    except Exception as e:
        return {'error': str(e)}

def monitor_continuous():
    """æŒç»­ç›‘æ§"""
    print("ğŸ” å¯åŠ¨å¢å¼ºç›‘æ§ç³»ç»Ÿ...")
    
    last_correlation_check = 0
    
    while True:
        status = get_detailed_status()
        current_time = time.time()
        
        print(f"\\n[{status['timestamp']}] ç³»ç»ŸçŠ¶æ€:")
        print("=" * 80)
        
        if 'error' in status:
            print(f"âŒ é”™è¯¯: {status['error']}")
        else:
            # è¿›ç¨‹çŠ¶æ€
            if status['process']:
                print("âœ… è®­ç»ƒè¿›ç¨‹è¿è¡Œä¸­")
                print(f"è¿›ç¨‹: {status['process']}")
            else:
                print("âŒ è®­ç»ƒè¿›ç¨‹æœªè¿è¡Œ")
            
            # GPUçŠ¶æ€
            if status['gpu']:
                gpu_lines = status['gpu'].split('\\n')
                for i, line in enumerate(gpu_lines):
                    if line.strip():
                        parts = line.split(', ')
                        if len(parts) >= 4:
                            mem_used, mem_total, util, temp = parts
                            print(f"GPU {i}: {mem_used}MB/{mem_total}MB ({util}% util, {temp}Â°C)")
            
            # æ—¥å¿—çŠ¶æ€
            if 'Epoch' in status['log']:
                print("ğŸ“Š è®­ç»ƒè¿›åº¦ä¿¡æ¯:")
                for line in status['log'].split('\\n')[-5:]:
                    if 'Epoch' in line or 'Training:' in line:
                        print(f"  {line}")
            
            # æ£€æŸ¥å†…å­˜é”™è¯¯
            if 'CUDA out of memory' in status['log']:
                print("âš ï¸  æ£€æµ‹åˆ°å†…å­˜é”™è¯¯")
            
            # æ¯2å°æ—¶æ£€æŸ¥ç›¸å…³æ€§
            if current_time - last_correlation_check >= 7200:
                print("ğŸ“ˆ æ£€æŸ¥ç›¸å…³æ€§æŠ¥å‘Š...")
                # è¿™é‡Œå¯ä»¥æ·»åŠ ç›¸å…³æ€§æ£€æŸ¥é€»è¾‘
                last_correlation_check = current_time
        
        print("=" * 80)
        time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡

if __name__ == "__main__":
    monitor_continuous()
'''
    
    with open("/nas/factor_forecasting/enhanced_monitor.py", "w") as f:
        f.write(monitoring_script)
    
    print("âœ… åˆ›å»ºäº†å¢å¼ºç›‘æ§è„šæœ¬")

def apply_all_fixes():
    """åº”ç”¨æ‰€æœ‰ä¿®å¤"""
    print("ğŸ”§ å¼€å§‹åº”ç”¨ç»ˆæå†…å­˜ä¼˜åŒ–...")
    
    create_robust_config()
    create_memory_optimized_launcher()
    patch_training_script_for_memory()
    create_monitoring_script()
    
    print("âœ… æ‰€æœ‰ä¼˜åŒ–å·²åº”ç”¨å®Œæˆ!")

if __name__ == "__main__":
    apply_all_fixes()
'''
