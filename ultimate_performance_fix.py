#!/usr/bin/env python3
"""
ç»ˆææ€§èƒ½ä¿®å¤è„šæœ¬
ä»æ ¹æœ¬ä¸Šè§£å†³GPUåˆ©ç”¨ç‡ä½ã€å†…å­˜ç¢ç‰‡åŒ–ã€æ•°æ®ç±»å‹é”™è¯¯ç­‰é—®é¢˜
"""

import os
import re
import subprocess
from pathlib import Path

def kill_all_training_processes():
    """å½»åº•æ¸…ç†æ‰€æœ‰è®­ç»ƒè¿›ç¨‹"""
    print("ğŸ§¹ æ¸…ç†æ‰€æœ‰è®­ç»ƒè¿›ç¨‹...")
    
    commands = [
        "pkill -f torchrun",
        "pkill -f unified_complete_training",
        "pkill -f python.*training",
        "nvidia-smi --gpu-reset-ecc=0,1,2,3 || true",
        "sleep 3"
    ]
    
    for cmd in commands:
        try:
            subprocess.run(cmd, shell=True, timeout=10)
            print(f"âœ“ æ‰§è¡Œ: {cmd}")
        except Exception as e:
            print(f"âš ï¸ {cmd} æ‰§è¡Œå¤±è´¥: {e}")

def fix_tensor_string_error():
    """ä¿®å¤Tensorå­—ç¬¦ä¸²ç±»å‹é”™è¯¯"""
    print("ğŸ”§ ä¿®å¤æ•°æ®ç±»å‹é”™è¯¯...")
    
    script_path = "/nas/factor_forecasting/unified_complete_training_v2_fixed.py"
    
    with open(script_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ä¿®å¤å¸¸è§çš„å­—ç¬¦ä¸²/Tensoræ··ç”¨é—®é¢˜
    fixes = [
        # ä¿®å¤target_columnsçš„å¤„ç†
        (r'if target_col in batch\[\'targets\'\]', r'if target_col in batch[\'targets\'].keys()'),
        (r'if target_col in targets', r'if target_col in targets.keys()'),
        (r'if col in predictions', r'if col in predictions.keys()'),
        (r'target_col in batch', r'target_col in list(batch.keys())'),
        
        # ä¿®å¤å­—å…¸é”®çš„æ¯”è¾ƒ
        (r'(\w+) in (\w+)\[\'(\w+)\'\]', r'\1 in list(\2[\'\3\'].keys()) if isinstance(\2[\'\3\'], dict) else \1 in \2[\'\3\']'),
    ]
    
    for pattern, replacement in fixes:
        content = re.sub(pattern, replacement, content)
    
    # æ·»åŠ ç±»å‹æ£€æŸ¥å‡½æ•°
    type_check_code = '''
def safe_key_check(key, container):
    """å®‰å…¨çš„é”®æ£€æŸ¥å‡½æ•°"""
    if isinstance(container, dict):
        return key in container
    elif hasattr(container, 'keys'):
        return key in container.keys()
    elif hasattr(container, '__contains__'):
        try:
            return key in container
        except TypeError:
            return False
    return False
'''
    
    # åœ¨å¯¼å…¥åæ·»åŠ è¾…åŠ©å‡½æ•°
    if 'def safe_key_check' not in content:
        import_end = content.find('# Import components')
        if import_end != -1:
            content = content[:import_end] + type_check_code + '\n' + content[import_end:]
    
    with open(script_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print("âœ“ æ•°æ®ç±»å‹é”™è¯¯å·²ä¿®å¤")

def create_optimized_4gpu_config():
    """åˆ›å»ºä¼˜åŒ–çš„4GPUé…ç½®"""
    print("âš™ï¸ åˆ›å»ºä¼˜åŒ–çš„4GPUé…ç½®...")
    
    config_content = """# ä¼˜åŒ–çš„4GPUé«˜æ€§èƒ½é…ç½®
model_type: AdvancedFactorForecastingTCNAttention
input_dim: 100
hidden_dim: 512       # é€‚ä¸­çš„éšè—å±‚ç»´åº¦
num_layers: 8         # é€‚ä¸­çš„å±‚æ•°  
num_heads: 8          # é€‚ä¸­çš„æ³¨æ„åŠ›å¤´æ•°
tcn_kernel_size: 3
tcn_dilation_factor: 2
dropout_rate: 0.1
attention_dropout: 0.05
target_columns: [nextT1d]  # å•ä¸€ç›®æ ‡å‡å°‘å†…å­˜å ç”¨
sequence_length: 30        # é€‚ä¸­çš„åºåˆ—é•¿åº¦
epochs: 200
batch_size: 512           # æ¯GPUæ‰¹æ¬¡å¤§å°
fixed_batch_size: 512
learning_rate: 0.0001
weight_decay: 0.01
gradient_clip_norm: 1.0
use_mixed_precision: true
accumulation_steps: 1
use_adaptive_batch_size: false
num_workers: 0
pin_memory: false
use_distributed: true     # å¯ç”¨åˆ†å¸ƒå¼è®­ç»ƒ
auto_resume: true
log_level: INFO
ic_report_interval: 7200
enable_ic_reporting: true
checkpoint_frequency: 10
save_all_checkpoints: false
output_dir: /nas/factor_forecasting/outputs
data_dir: /nas/feature_v2_10s
train_start_date: 2018-01-02
train_end_date: 2018-10-31   # å‰10ä¸ªæœˆæ•°æ®
val_start_date: 2018-11-01
val_end_date: 2018-11-30
test_start_date: 2018-12-01
test_end_date: 2018-12-31
enforce_next_year_prediction: false
enable_yearly_rolling: false
min_train_years: 1
rolling_window_years: 1
shuffle_buffer_size: 256

# æ€§èƒ½ä¼˜åŒ–å‚æ•°
world_size: 4
backend: nccl
enable_gradient_checkpointing: false  # æé«˜é€Ÿåº¦
torch_compile: false
use_channels_last: true
"""
    
    with open("/nas/factor_forecasting/optimized_4gpu_config.yaml", "w") as f:
        f.write(config_content)
    
    print("âœ“ 4GPUé…ç½®å·²åˆ›å»º")

def create_performance_launcher():
    """åˆ›å»ºé«˜æ€§èƒ½å¯åŠ¨è„šæœ¬"""
    print("ğŸš€ åˆ›å»ºé«˜æ€§èƒ½å¯åŠ¨è„šæœ¬...")
    
    launcher_content = '''#!/bin/bash
# é«˜æ€§èƒ½4GPUè®­ç»ƒå¯åŠ¨è„šæœ¬

# è®¾ç½®ç¯å¢ƒå˜é‡ä¼˜åŒ–æ€§èƒ½
export CUDA_VISIBLE_DEVICES=0,1,2,3
export PYTORCH_CUDA_ALLOC_CONF="max_split_size_mb:512,expandable_segments:True"
export NCCL_DEBUG=INFO
export NCCL_TREE_THRESHOLD=0
export OMP_NUM_THREADS=32
export CUDA_LAUNCH_BLOCKING=0
export PYTHONUNBUFFERED=1

# è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒå‚æ•°
export MASTER_ADDR=localhost
export MASTER_PORT=12355
export WORLD_SIZE=4

cd /nas/factor_forecasting
source venv/bin/activate

echo "ğŸ§¹ æ¸…ç†GPUç¼“å­˜..."
python -c "import torch; [torch.cuda.empty_cache() for _ in range(4)]" 2>/dev/null || true

echo "ğŸš€ å¯åŠ¨4GPUåˆ†å¸ƒå¼è®­ç»ƒ..."
torchrun \\
    --nproc_per_node=4 \\
    --master_addr=localhost \\
    --master_port=12355 \\
    unified_complete_training_v2_fixed.py \\
    --config optimized_4gpu_config.yaml \\
    > training_4gpu_optimized.log 2>&1 &

echo "è®­ç»ƒå·²å¯åŠ¨ï¼ŒPID: $!"
echo "æ—¥å¿—æ–‡ä»¶: training_4gpu_optimized.log"
echo "ç›‘æ§å‘½ä»¤: tail -f training_4gpu_optimized.log"
'''
    
    with open("/nas/factor_forecasting/launch_4gpu_optimized.sh", "w") as f:
        f.write(launcher_content)
    
    # è®¾ç½®æ‰§è¡Œæƒé™
    os.chmod("/nas/factor_forecasting/launch_4gpu_optimized.sh", 0o755)
    print("âœ“ å¯åŠ¨è„šæœ¬å·²åˆ›å»º")

def create_performance_monitor():
    """åˆ›å»ºæ€§èƒ½ç›‘æ§è„šæœ¬"""
    print("ğŸ“Š åˆ›å»ºæ€§èƒ½ç›‘æ§è„šæœ¬...")
    
    monitor_content = '''#!/usr/bin/env python3
"""
é«˜æ€§èƒ½è®­ç»ƒç›‘æ§è„šæœ¬
å®æ—¶ç›‘æ§4GPUè®­ç»ƒçŠ¶æ€å’Œæ€§èƒ½æŒ‡æ ‡
"""

import subprocess
import time
import re
import json
from datetime import datetime
from pathlib import Path

class PerformanceMonitor:
    def __init__(self):
        self.last_correlation_check = 0
        self.start_time = time.time()
        
    def get_gpu_utilization(self):
        """è·å–GPUåˆ©ç”¨ç‡è¯¦æƒ…"""
        try:
            result = subprocess.run([
                'nvidia-smi', 
                '--query-gpu=index,name,memory.used,memory.total,utilization.gpu,utilization.memory,temperature.gpu,power.draw',
                '--format=csv,noheader,nounits'
            ], capture_output=True, text=True)
            
            gpus = []
            for line in result.stdout.strip().split('\\n'):
                if line.strip():
                    parts = [p.strip() for p in line.split(',')]
                    if len(parts) >= 7:
                        gpus.append({
                            'id': parts[0],
                            'name': parts[1],
                            'mem_used': int(parts[2]),
                            'mem_total': int(parts[3]),
                            'gpu_util': int(parts[4]),
                            'mem_util': int(parts[5]),
                            'temp': int(parts[6]),
                            'power': float(parts[7]) if parts[7] != '[N/A]' else 0
                        })
            return gpus
        except Exception as e:
            print(f"GPUçŠ¶æ€è·å–å¤±è´¥: {e}")
            return []
    
    def get_cpu_info(self):
        """è·å–CPUä¿¡æ¯"""
        try:
            # CPUåˆ©ç”¨ç‡
            cpu_result = subprocess.run(['top', '-bn1'], capture_output=True, text=True)
            cpu_line = ""
            for line in cpu_result.stdout.split('\\n'):
                if 'Cpu(s)' in line:
                    cpu_line = line
                    break
            
            # æå–CPUä½¿ç”¨ç‡
            cpu_usage = 0
            if 'us' in cpu_line:
                match = re.search(r'(\\d+\\.\\d+)%us', cpu_line)
                if match:
                    cpu_usage = float(match.group(1))
            
            return {'cpu_usage': cpu_usage, 'cpu_line': cpu_line}
        except Exception as e:
            return {'cpu_usage': 0, 'cpu_line': f'è·å–å¤±è´¥: {e}'}
    
    def get_memory_info(self):
        """è·å–å†…å­˜ä¿¡æ¯"""
        try:
            result = subprocess.run(['free', '-h'], capture_output=True, text=True)
            lines = result.stdout.strip().split('\\n')
            for line in lines:
                if line.startswith('Mem:'):
                    parts = line.split()
                    return {
                        'total': parts[1],
                        'used': parts[2],
                        'free': parts[3],
                        'available': parts[6] if len(parts) > 6 else parts[3]
                    }
        except Exception as e:
            return {'error': str(e)}
    
    def get_training_processes(self):
        """è·å–è®­ç»ƒè¿›ç¨‹ä¿¡æ¯"""
        try:
            result = subprocess.run(['ps', 'aux'], capture_output=True, text=True)
            processes = []
            for line in result.stdout.split('\\n'):
                if 'unified_complete_training' in line and 'grep' not in line:
                    parts = line.split()
                    if len(parts) >= 11:
                        processes.append({
                            'pid': parts[1],
                            'cpu': parts[2],
                            'mem': parts[3],
                            'command': ' '.join(parts[10:])
                        })
            return processes
        except Exception as e:
            return []
    
    def get_training_progress(self):
        """è·å–è®­ç»ƒè¿›åº¦"""
        try:
            log_file = Path('/nas/factor_forecasting/training_4gpu_optimized.log')
            if log_file.exists():
                with open(log_file, 'r') as f:
                    content = f.read()
                
                # æå–æœ€æ–°çš„epochä¿¡æ¯
                epoch_pattern = r'Epoch (\\d+) Training: (\\d+)it \\[([^,]+), ([^]]+)\\]'
                matches = re.findall(epoch_pattern, content)
                
                if matches:
                    epoch, iterations, time_elapsed, time_per_it = matches[-1]
                    return {
                        'epoch': int(epoch),
                        'iterations': int(iterations),
                        'time_elapsed': time_elapsed,
                        'time_per_iteration': time_per_it,
                        'has_errors': 'ERROR' in content[-1000:]  # æ£€æŸ¥æœ€è¿‘1000å­—ç¬¦
                    }
        except Exception as e:
            pass
        
        return None
    
    def check_correlations(self):
        """æ£€æŸ¥ç›¸å…³æ€§æŠ¥å‘Š"""
        try:
            output_dir = Path('/nas/factor_forecasting/outputs')
            if output_dir.exists():
                json_files = list(output_dir.glob('**/*.json'))
                if json_files:
                    latest_file = max(json_files, key=lambda p: p.stat().st_mtime)
                    with open(latest_file, 'r') as f:
                        data = json.load(f)
                    
                    if 'correlations' in data:
                        return data['correlations']
        except Exception:
            pass
        
        return {}
    
    def calculate_efficiency(self, gpus):
        """è®¡ç®—ç¡¬ä»¶æ•ˆç‡"""
        if not gpus:
            return {'gpu_efficiency': 0, 'memory_efficiency': 0}
        
        total_gpu_util = sum(gpu['gpu_util'] for gpu in gpus)
        total_mem_util = sum(gpu['mem_util'] for gpu in gpus)
        
        gpu_efficiency = total_gpu_util / len(gpus)
        memory_efficiency = total_mem_util / len(gpus)
        
        return {
            'gpu_efficiency': gpu_efficiency,
            'memory_efficiency': memory_efficiency,
            'total_power': sum(gpu['power'] for gpu in gpus)
        }
    
    def monitor(self):
        """ä¸»ç›‘æ§å¾ªç¯"""
        print("ğŸš€ 4GPUé«˜æ€§èƒ½è®­ç»ƒç›‘æ§ç³»ç»Ÿ")
        print("=" * 100)
        
        while True:
            current_time = time.time()
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            runtime = current_time - self.start_time
            
            print(f"\\n[{timestamp}] è¿è¡Œæ—¶é—´: {runtime/3600:.1f}å°æ—¶")
            print("=" * 100)
            
            # GPUçŠ¶æ€
            gpus = self.get_gpu_utilization()
            if gpus:
                print("ğŸ“Š GPUçŠ¶æ€:")
                for gpu in gpus:
                    mem_percent = (gpu['mem_used'] / gpu['mem_total']) * 100
                    print(f"  GPU {gpu['id']}: {gpu['gpu_util']:3d}% åˆ©ç”¨ç‡ | "
                          f"{gpu['mem_used']:5d}MB/{gpu['mem_total']}MB ({mem_percent:4.1f}%) | "
                          f"{gpu['temp']:2d}Â°C | {gpu['power']:5.1f}W")
                
                # æ•ˆç‡åˆ†æ
                efficiency = self.calculate_efficiency(gpus)
                print(f"\\nâš¡ æ•ˆç‡æŒ‡æ ‡:")
                print(f"  å¹³å‡GPUåˆ©ç”¨ç‡: {efficiency['gpu_efficiency']:.1f}%")
                print(f"  å¹³å‡å†…å­˜åˆ©ç”¨ç‡: {efficiency['memory_efficiency']:.1f}%")
                print(f"  æ€»åŠŸè€—: {efficiency['total_power']:.1f}W")
            
            # CPUçŠ¶æ€
            cpu_info = self.get_cpu_info()
            print(f"\\nğŸ”¥ CPUçŠ¶æ€:")
            print(f"  åˆ©ç”¨ç‡: {cpu_info['cpu_usage']:.1f}% (128æ ¸)")
            
            # å†…å­˜çŠ¶æ€
            mem_info = self.get_memory_info()
            if 'error' not in mem_info:
                print(f"  å†…å­˜: {mem_info['used']}/{mem_info['total']} (å¯ç”¨: {mem_info['available']})")
            
            # è®­ç»ƒè¿›ç¨‹
            processes = self.get_training_processes()
            print(f"\\nğŸƒ è®­ç»ƒè¿›ç¨‹: {len(processes)}ä¸ª")
            for proc in processes[:4]:  # æ˜¾ç¤ºå‰4ä¸ª
                print(f"  PID {proc['pid']}: CPU {proc['cpu']}%, å†…å­˜ {proc['mem']}%")
            
            # è®­ç»ƒè¿›åº¦
            progress = self.get_training_progress()
            if progress:
                print(f"\\nğŸ“ˆ è®­ç»ƒè¿›åº¦:")
                print(f"  å½“å‰Epoch: {progress['epoch']}")
                print(f"  å®Œæˆè¿­ä»£: {progress['iterations']}")
                print(f"  å·²ç”¨æ—¶é—´: {progress['time_elapsed']}")
                print(f"  æ¯æ¬¡è¿­ä»£: {progress['time_per_iteration']}")
                
                if progress['has_errors']:
                    print("  âš ï¸ æ£€æµ‹åˆ°é”™è¯¯")
                else:
                    print("  âœ… è¿è¡Œæ­£å¸¸")
            else:
                print("\\nâŒ æœªæ£€æµ‹åˆ°è®­ç»ƒè¿›åº¦")
            
            # æ¯2å°æ—¶æ£€æŸ¥ç›¸å…³æ€§
            if current_time - self.last_correlation_check >= 7200:
                print("\\nğŸ“Š ç›¸å…³æ€§æ£€æŸ¥...")
                correlations = self.check_correlations()
                if correlations:
                    for target, data in correlations.items():
                        if isinstance(data, dict):
                            in_sample = data.get('in_sample_ic', 'N/A')
                            out_sample = data.get('out_sample_ic', 'N/A')
                            print(f"  {target}: In-sample={in_sample}, Out-sample={out_sample}")
                else:
                    print("  æš‚æ— ç›¸å…³æ€§æ•°æ®")
                
                self.last_correlation_check = current_time
            
            print("=" * 100)
            time.sleep(30)  # 30ç§’æ£€æŸ¥ä¸€æ¬¡

if __name__ == "__main__":
    monitor = PerformanceMonitor()
    try:
        monitor.monitor()
    except KeyboardInterrupt:
        print("\\n\\nğŸ‘‹ ç›‘æ§ç»“æŸ")
'''
    
    with open("/nas/factor_forecasting/performance_monitor.py", "w") as f:
        f.write(monitor_content)
    
    print("âœ“ æ€§èƒ½ç›‘æ§è„šæœ¬å·²åˆ›å»º")

def apply_all_fixes():
    """åº”ç”¨æ‰€æœ‰ä¿®å¤"""
    print("ğŸ”§ å¼€å§‹åº”ç”¨ç»ˆææ€§èƒ½ä¿®å¤...")
    print("=" * 60)
    
    kill_all_training_processes()
    fix_tensor_string_error()
    create_optimized_4gpu_config()
    create_performance_launcher()
    create_performance_monitor()
    
    print("=" * 60)
    print("âœ… æ‰€æœ‰ä¿®å¤å·²å®Œæˆ!")
    print("ğŸš€ å‡†å¤‡å¯åŠ¨é«˜æ€§èƒ½4GPUè®­ç»ƒ...")

if __name__ == "__main__":
    apply_all_fixes()
